[{"content":"记录一下使用Hugo生成静态博客，并通过githubPages自动化部署的过程。\n这里，我的目标是：\n 使用blog-source作为原始的内容仓库，\u0026lt;your-name\u0026gt;.github.io作为实际的githubPages仓库 通过github Action将两者串联起来，原始内容提交变更时，自动触发内容生成并发布  这样的好处是，可以将blog-source作为私有仓库，并能直接以\u0026lt;your-name\u0026gt;.github.io作为URL。且通过github action实现CICD，解放双手实现自动化。这里我画了一张图，便于理解：\nHugo 安装Hugo，然后初始化\n# macOS install hugo brew install hugo  # create site project hugo new site blog-source 选择你中意的主题并安装\ncd blog-source git init  # add paperMod as theme git submodule add https://github.com/adityatelange/hugo-PaperMod themes/paperMod 添加文章并启动demo\nhugo new posts/my-first-post.md # start demo for preview hugo server -D 创建一个额外的仓库，这里我创建一个名为blog-source的仓库并作为刚才创建的blog-source的远端仓库\ncd blog-source git init git remote add origin \u0026lt;your-remove-git\u0026gt; GithubPages 创建一个githubPages仓库，名称必须是\u0026lt;your-name\u0026gt;.github.io。DOC\nConnection 创建sshKey: ssh-keygen -t rsa -b 4096 -C \u0026quot;$(git config user.email)\u0026quot; -f gh-pages -N \u0026quot;\u0026quot;\n将私钥gh-pages内容复制，并在blog-source仓库的Settings-\u0026gt;Secrets-\u0026gt;Actions创建secret变量\n将公钥gh-pages.pub内容复制，并作为\u0026lt;your-name\u0026gt;.github.io的Deploy Key，记得勾选读写权限\n创建github workflow文件.github/workflows/gh-pages.yml，其内容如下所示：\nname: github pages  on:  push:  branches:  - master  # Set a branch to deploy, my branch is master  pull_request:  jobs:  deploy:  runs-on: ubuntu-20.04  steps:  - uses: actions/checkout@v2  with:  submodules: true # Fetch Hugo themes (true OR recursive)  fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod   - name: Setup Hugo  uses: peaceiris/actions-hugo@v2  with:  hugo-version: \u0026#39;0.99.1\u0026#39;  # extended: true   - name: Build  run: hugo --minify   - name: Deploy  uses: peaceiris/actions-gh-pages@v3  with:  external_repository: \u0026lt;your-name\u0026gt;/\u0026lt;your-name\u0026gt;.github.io  publish_branch: master  # the secret key  deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}  publish_dir: ./public 完成后，在blog-source仓库提交代码并push即可触发workflow，可在仓库的Actions功能项下查看运行情况。\n若无意外，稍等片刻(估计是因为Github同步并非完全实时)，即可通过\u0026lt;your-name\u0026gt;/\u0026lt;your-name\u0026gt;.github.io访问博客了\n总结 综上所述，使用hugo生成静态网站，创建githubPages项目其实并不难，主要难点在于如何通过githubAction将两者链接起来，实现CICD。遇到问题，建议多多翻阅官方文档，一定是能解决的。\n参考  https://github.com/peaceiris/actions-gh-pages https://docs.github.com/en/pages/getting-started-with-github-pages/about-github-pages https://gohugo.io/hosting-and-deployment/hosting-on-github/  ","permalink":"https://erenming.github.io/posts/hugo-with-githubpages/","summary":"记录一下使用Hugo生成静态博客，并通过githubPages自动化部署的过程。\n这里，我的目标是：\n 使用blog-source作为原始的内容仓库，\u0026lt;your-name\u0026gt;.github.io作为实际的githubPages仓库 通过github Action将两者串联起来，原始内容提交变更时，自动触发内容生成并发布  这样的好处是，可以将blog-source作为私有仓库，并能直接以\u0026lt;your-name\u0026gt;.github.io作为URL。且通过github action实现CICD，解放双手实现自动化。这里我画了一张图，便于理解：\nHugo 安装Hugo，然后初始化\n# macOS install hugo brew install hugo  # create site project hugo new site blog-source 选择你中意的主题并安装\ncd blog-source git init  # add paperMod as theme git submodule add https://github.com/adityatelange/hugo-PaperMod themes/paperMod 添加文章并启动demo\nhugo new posts/my-first-post.md # start demo for preview hugo server -D 创建一个额外的仓库，这里我创建一个名为blog-source的仓库并作为刚才创建的blog-source的远端仓库\ncd blog-source git init git remote add origin \u0026lt;your-remove-git\u0026gt; GithubPages 创建一个githubPages仓库，名称必须是\u0026lt;your-name\u0026gt;.github.io。DOC\nConnection 创建sshKey: ssh-keygen -t rsa -b 4096 -C \u0026quot;$(git config user.","title":"使用Hugo部署GithubPages"},{"content":"不知为何，写博客总是断断续续，距离上次更新已过去快一年了，直至如今面试碰壁方才后悔莫及。\n事实上，写博客对于对于知识的小伙理解非常有好处，毕竟要让别人听得懂，首先自己得更懂才行嘛。因为，通常学习一项新知识，通常需要理论学习-实践-总结输出三个阶段，而我往往只完成了第一阶段便草草了事，无法对知识有更深入的理解。因此，我打算重启我的博客之路，持续学习持续输出。\n之前博客用过Hexo，也用过博客园等等，最近看到hugo的paperMod主题非常讨喜，因此打算彻底切换到hugo+paperMod，也算起个好头吧。之前的文章也会从博客园迁移到hugo上，不过后续两边也会尽量同步更新。\n然后，也打算支持中英文双语，主要是为了提升自己的英文水平，以便能和世界上的程序员更好地交流。不过目前主打还是中文，母语写起来还是方便点，英文会挑选文章进行编写翻译，同时英文文章也会同步发布在Medium上。\n此外，为了降低断更的概率、提高文章质量，我在这里给自己立一个flag，即每月至少更新一篇文章，文章长度适宜、做到通俗易懂、绝不模棱两可故作高深\n","permalink":"https://erenming.github.io/posts/restart-my-blog/","summary":"不知为何，写博客总是断断续续，距离上次更新已过去快一年了，直至如今面试碰壁方才后悔莫及。\n事实上，写博客对于对于知识的小伙理解非常有好处，毕竟要让别人听得懂，首先自己得更懂才行嘛。因为，通常学习一项新知识，通常需要理论学习-实践-总结输出三个阶段，而我往往只完成了第一阶段便草草了事，无法对知识有更深入的理解。因此，我打算重启我的博客之路，持续学习持续输出。\n之前博客用过Hexo，也用过博客园等等，最近看到hugo的paperMod主题非常讨喜，因此打算彻底切换到hugo+paperMod，也算起个好头吧。之前的文章也会从博客园迁移到hugo上，不过后续两边也会尽量同步更新。\n然后，也打算支持中英文双语，主要是为了提升自己的英文水平，以便能和世界上的程序员更好地交流。不过目前主打还是中文，母语写起来还是方便点，英文会挑选文章进行编写翻译，同时英文文章也会同步发布在Medium上。\n此外，为了降低断更的概率、提高文章质量，我在这里给自己立一个flag，即每月至少更新一篇文章，文章长度适宜、做到通俗易懂、绝不模棱两可故作高深","title":"重启博客之路"},{"content":"为什么需要内存分配器？ 总说周知，内存作为一种相对稀缺的资源，在操作系统中以虚拟内存的形式来作为一种内存抽象提供给进程，这里可以简单地把它看做一个连续的地址集合{0, 1, 2, ..., M}，由栈空间、堆空间、代码片、数据片等地址空间段组合而成，如下图所示(出自CS:APP3e, Bryant and O\u0026rsquo;Hallaron的第9章第9节)\n这里我们重点关注Heap（堆），堆是一块动态的虚拟内存地址空间。在C语言中，我们通常使用malloc来申请内存以及使用free来释放内存，也许你想问，这样不就足够了吗？但是，这种手动的内存管理会带来很多问题，比如：\n 给程序员带来额外的心智负担，必须得及时释放掉不再使用的内存空间，否则就很容易出现内存泄露 随着内存的不断申请与释放，会产生大量的内存碎片，这将大大降低内存的利用率  因此，正确高效地管理内存空间是非常有必要的，常见的技术实现有Sequential allocation, Free-List allocation等。那么，在Go中，内存是如何被管理的呢？\n 注：此为Go1.13.6的实现逻辑，随版本更替某些细节会有些许不同\n 实现原理 Go的内存分配器是基于TCMalloc设计的，因此我建议你先行查阅，这将有利于理解接下来的内容。\n大量工程经验证明，程序中的小对象占了绝大部分，且生命周期都较为短暂。因此，Go将内存划分为各种类别(Class)，并各自形成Free-List。相较于单一的Free-List分配器，分类后主要有以下优点：\n  其一方面减少不必要的搜索时间，因为对象只需要在其所属类别的空闲链表中搜索即可\n  另一方面减少了内存碎片化，同一类别的空闲链表，每个对象分配的空间都是一样大小(不足则补齐)，因此该链表除非无空闲空间，否则总能分配空间，避免了内存碎片\n  那么，Go内存分配器具体是如何实现的呢？接下来，我将以自顶向下的方式，从宏观到微观，层层拨开她的神秘面纱。\n数据结构 首先，介绍Go内存分配中相关的数据结构。其总体概览图如下所示：\nheapArena 在操作系统中，我们一般把堆看做是一块连续的虚拟内存空间。\nGo将其划分为数个相同大小的连续空间块，称之arena，其中，heapArena则作为arena空间的管理单元，其结构如下所示：\ntype heapArena struct {  bitmap [heapArenaBitmapBytes]byte  spans [pagesPerArena]*mspan  ... }  bitmap: 表示arena区域中的哪些地址保存了对象，哪些地址保存了指针 spans: 表示arena区域中的哪些操作系统页(8K)属于哪些mspan  mheap 然后，则是核心角色mheap了，它是Go内存管理中的核心数据结构，作为全局唯一变量，其结构如下所示：\ntype mheap struct { \tfree mTreap  ...  allspans []*mspan  ...  arenas [1 \u0026lt;\u0026lt; arenaL1Bits]*[1 \u0026lt;\u0026lt; arenaL2Bits]*heapArena  ...  central [numSpanClasses]struct { \tmcentral mcentral \tpad [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte \t} }  free: 使用树堆的结构来保存各种类别的空闲mspan allspans: 用以记录了分配过了的mspan arenas: 表示其覆盖的所有arena区域，通过虚拟内存地址计算得到下标索引 central: 表示其覆盖的所有mcentral，一共134个，对应67个类别  mcentral 而mcentral充当mspan的中心管理员，负责管理某一类别的mspan，其结构如下：\ntype mcentral struct { \tlock mutex \tspanclass spanClass \tnonempty mSpanList \tempty mSpanList }  lock: 全局互斥锁，因为多个线程会并发请求 spanclass：mspan类别 nonempty：mspan的双端链表，且其中至少有一个mspan包含空闲对象 empty：mspan的双端链表，但不确定其中的mspan是否包含空闲对象  mcache mcache充当mspan的线程本地缓存角色，其与线程处理器(P)一一绑定。\n这样呢，当mcache有空闲mspan时，则无需向mcentral申请，因此可以避免诸多不必要的锁消耗。结构如下所示：\ntype mcache struct {  ...  alloc [numSpanClasses]*mspan  ... }  alloc: 表示各个类别的mspan  mspan mspan作为虚拟内存的实际管理单元，管理着一片内存空间(npages个页)，其结构如下所示：\ntype mspan struct { \tnext *mspan // 指向下一个mspan \tprev *mspan // 指向前一个mspan  ... \tnpages uintptr  freeindex uintptr  nelems uintptr // 总对象个数  ...  allocBits *gcBits \tgcmarkBits *gcBits }  next指针指向下一个mspan，prev指针指向前一个mspan，因此各个mspan彼此之间形成一个双端链表，并被runtime.mSpanList作为链表头。 npages：mspan所管理的页的数量 freeindex：空闲对象的起始位置，如果freeindex等于nelems时，则代表此mspan无空闲对象可分配了 allocBits：标记哪些元素已分配，哪些未分配。与freeindex结合，可跳过已分配的对象 gcmarkBits：标记哪些对象存活，每次GC结束时，将其设为allocBits  通过上述对Go内存管理中各个关键数据结构的介绍，想必现在，我们已经对其有了一个大概的轮廓。接下来，让我们继续探究，看看Go具体是如何利用这些数据结构来实现高效的内存分配算法\n算法 分配内存 内存分配算法，其主要函数为runtime.mallocgc，其基本步骤简述如下：\n 判断待分配对象的大小 若对象小于maxTinySize（16B），且不为指针，则执行微对象分配算法 若对象小于maxSmallSize（32KB），则执行小对象分配算法 否则，则执行大对象分配算法  在微对象以及小对象分配过程中，如果span中找不到足够的空闲空间，Go会触发层级的内存分配申请策略。其基本步骤如下：\n 先从mcache寻找对应类别的span，若有空闲对象，则成功返回 若无，则向mcentral申请，分别从nonempty和empty中寻找匹配的span，若找到，则成功返回 若还未找到，则继续向mheap申请，从mheap.free中寻找，若找到，则成功返回 若未找到，则需扩容，从关联的arena中申请，若关联的arena中空间也不足，则向OS申请额外的arena 扩容完毕后，继续从mheap.free中寻找，若仍未找到，则抛出错误  学到了什么  本地线程缓存，提高性能：通过mcache缓存小对象的span，并优先在mcache中分配，降低锁竞争 无处不在的BitMap应用场景：通过二进制位来映射对象，例如mspan.allocBits用以表示对象是否分配 多级分配策略：自底向上，性能损耗：低-\u0026gt;高，频率：高-\u0026gt;低，能有效提高性能，思想上类似CPU中的多级缓存  总结 本文主要介绍了Go内存分配中的一些重要组件以及分配算法。可以看到，其主要思想还是基于TCMalloc的策略，将对象根据大小分类，并使用不同的分配策略。此外，还采用逐层的内存申请策略，大大提高内存分配的性能。\n参考  https://google.github.io/tcmalloc/ http://goog-perftools.sourceforge.net/doc/tcmalloc.html https://medium.com/@ankur_anand/a-visual-guide-to-golang-memory-allocator-from-ground-up-e132258453ed https://www.cnblogs.com/zkweb/p/7880099.html https://www.cnblogs.com/luozhiyun/p/14349331.html https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/  ","permalink":"https://erenming.github.io/posts/memory-allocator-in-go/","summary":"为什么需要内存分配器？ 总说周知，内存作为一种相对稀缺的资源，在操作系统中以虚拟内存的形式来作为一种内存抽象提供给进程，这里可以简单地把它看做一个连续的地址集合{0, 1, 2, ..., M}，由栈空间、堆空间、代码片、数据片等地址空间段组合而成，如下图所示(出自CS:APP3e, Bryant and O\u0026rsquo;Hallaron的第9章第9节)\n这里我们重点关注Heap（堆），堆是一块动态的虚拟内存地址空间。在C语言中，我们通常使用malloc来申请内存以及使用free来释放内存，也许你想问，这样不就足够了吗？但是，这种手动的内存管理会带来很多问题，比如：\n 给程序员带来额外的心智负担，必须得及时释放掉不再使用的内存空间，否则就很容易出现内存泄露 随着内存的不断申请与释放，会产生大量的内存碎片，这将大大降低内存的利用率  因此，正确高效地管理内存空间是非常有必要的，常见的技术实现有Sequential allocation, Free-List allocation等。那么，在Go中，内存是如何被管理的呢？\n 注：此为Go1.13.6的实现逻辑，随版本更替某些细节会有些许不同\n 实现原理 Go的内存分配器是基于TCMalloc设计的，因此我建议你先行查阅，这将有利于理解接下来的内容。\n大量工程经验证明，程序中的小对象占了绝大部分，且生命周期都较为短暂。因此，Go将内存划分为各种类别(Class)，并各自形成Free-List。相较于单一的Free-List分配器，分类后主要有以下优点：\n  其一方面减少不必要的搜索时间，因为对象只需要在其所属类别的空闲链表中搜索即可\n  另一方面减少了内存碎片化，同一类别的空闲链表，每个对象分配的空间都是一样大小(不足则补齐)，因此该链表除非无空闲空间，否则总能分配空间，避免了内存碎片\n  那么，Go内存分配器具体是如何实现的呢？接下来，我将以自顶向下的方式，从宏观到微观，层层拨开她的神秘面纱。\n数据结构 首先，介绍Go内存分配中相关的数据结构。其总体概览图如下所示：\nheapArena 在操作系统中，我们一般把堆看做是一块连续的虚拟内存空间。\nGo将其划分为数个相同大小的连续空间块，称之arena，其中，heapArena则作为arena空间的管理单元，其结构如下所示：\ntype heapArena struct {  bitmap [heapArenaBitmapBytes]byte  spans [pagesPerArena]*mspan  ... }  bitmap: 表示arena区域中的哪些地址保存了对象，哪些地址保存了指针 spans: 表示arena区域中的哪些操作系统页(8K)属于哪些mspan  mheap 然后，则是核心角色mheap了，它是Go内存管理中的核心数据结构，作为全局唯一变量，其结构如下所示：\ntype mheap struct { \tfree mTreap  ...  allspans []*mspan  .","title":"浅析Go内存分配器的实现"},{"content":"最近做了许多有关Go内存优化的工作，总结了一些定位、调优方面的套路和经验，于是，想通过这篇文章与大家分享讨论。\n发现问题 性能优化领域有一条总所周知的铁律，即：不要过早地优化。编写一个程序，首先应该保证其功能的正确性，以及诸如设计是否合理、需求等是否满足，过早地优化只会引入不必要的复杂度以及设计不合理等各种问题。\n那么何时才能开始优化呢？一句话，问题出现时。诸如程序出现频繁OOM，CPU使用率异常偏高等情况。如今，在这微服务盛行的时代，公司内部都会拥有一套或简单或复杂的监控系统，当系统给你发出相关告警时，你就要开始重视起来了。\n问题定位 1. 查看内存曲线 首先，当程序发生OOM时，首先应该查看程序的内存使用量曲线，可以通过现有监控系统查看，或者prometheus之类的开源工具。\n曲线一般都是呈上升趋势，比如goroutine泄露的曲线一般是使用量缓慢上升直至OOM，而内存分配不合理往往时在高负载时快速攀升以致OOM。\n2. 问题复现 这块是可选项，但是最好能保证复现。如果能在本地或debug环境复现问题，这将非常有利于我们反复进行测试和验证。\n3. 使用pprof定位 Go官方工具提供了pporf来专门用以性能问题定位，首先得在程序中开启pprof收集功能，这里假定问题程序已开启pprof。(对这块不够了解的同学，建议通过这两篇文章(1, 2)学习下pprof工具的基本用法)\n接下来，我们复现问题场景，并及时获取heap和groutine的采样信息。\n 获取heap信息: curl http://loalhost:6060/debug/pprof/heap -o h1.out 获取groutine信息：curl http://loalhost:6060/debug/pprof/goroutine -o g1.out  这里你可能想问，这样就够了吗？\n当然不是，只获取一份样本信息是不够的。内存使用量是不断变化的(通常是上升)，因此我们需要的也是期间heap、gourtine信息的变化信息，而非瞬时值。一般来说，我们需要一份正常情况下的样本信息，一份或多份内存升高期间的样本信息。\n数据收集完毕后，我们按照如下3个方面来排查定位。\n排查goroutine泄露 使用命令go tool pprof --base g1.out g2.out ，比较goroutine信息来判断是否有goroutine激增的情况。\n进入交互界面后，输入top命令，查看期间goroutine的变化。\n同时可执行go tool pprof --base g2.out g3.out来验证。我之前写了的一篇实战文章，记录了goroutine泄露的排查过程。\n排查内存使用量 使用命令go tool pprof --base h1.out h2.out，比较当前堆内存的使用量信息来判断内存使用量。\n进入交互界面后，输入top命令，查看期间堆内存使用量的变化。\n排查内存分配量 当上述排查方向都没发现问题时，那就要查看期间是否有大量的内存申请了，以至于GC都来不及回收。使用命令go tool pprof --alloc_space --base h1.out h2.out，通过比较前后内存分配量来判断是否有分配不合理的现象。\n进入交互界面后，输入top命令，查看期间堆内存分配量的变化。\n一般来说，通过上述3个方面的排查，我们基本就能定位出究竟是哪方面的问题导致内存激增了。我们可以通过web命令，更为直观地查看问题函数(方法)的完整调用链。\n问题优化 定位到问题根因后，接下来就是优化阶段了。这个阶段需要对Go本身足够熟悉，还得对问题程序的业务逻辑有所了解。\n我梳理了一些常见的优化手段，仅供参考。实际场景还是得实际分析。\ngoroutine泄露 这种问题还是比较好修复的，需要显式地保证goroutine能正确退出，而非以一些自以为的假设来保证。例如，通过传递context.Context对象来显式退出\ngo func(ctx context.Context) {  for {  select {  case \u0026lt;-ctx.Done():  default:  }  ...  } }(ctx) 对象复用 在一些热点代码处，我们应该避免每次调用都申请新的内存，因为在极端情况下，内存分配速度可能会超过GC的速度，从而导致内存激增。这种情况下，我们可以采取复用对象的方式，例如我们可以使用sync.Pool来复用对象\nvar pool = sync.Pool{New: func() interface{} { return make([]byte, 4096) }}  func fn() { \tbuf := pool.Get().([]byte) // takes from pool or calls New \t// do work \tpool.Put(buf) // returns buf to the pool } 避免[]byte和string转换 在Go中，使用string()或[]byte()来实现[]byte和string的类型转换，会额外申请一块内存来复制。我们可以通过一些技巧来避免复制，例如*(*[]byte)(unsafe.Pointer(\u0026amp;s))来实现string转[]byte\n除此之外，还有很多优化方法，可以看看dave cheney大神的这篇文章，真得写得非常好。\n优化验证 最后一步，我们需要验证优化的结果，毕竟你至少得说服自己，你的优化是的确有成效的。\n除了通过复现测试来验证有效性外的，还可以编写Benchmark测试用例来比较优化前后的内存分配情况（在Benchmark测试用例中加入一行b.ReportAllocs()，即可得到内存分配量信息）\n总结 性能调优是一项必备但是较为困难的技能，不仅需要熟悉语言、操作系统等基本知识，还需要一定的经验积累。\n本文介绍了针对Go程序内存问题的发现、定位、优化以及验证，希望能对你排查内存问题有所帮助（还有某些情况未能没考虑到，欢迎评论区参与讨论）。\n参考  https://dave.cheney.net/high-performance-go-workshop/dotgo-paris.html https://golang.org/pkg/net/http/pprof/ https://www.freecodecamp.org/news/how-i-investigated-memory-leaks-in-go-using-pprof-on-a-large-codebase-4bec4325e192/  ","permalink":"https://erenming.github.io/posts/memory-optimize-best-practice-for-golang/","summary":"最近做了许多有关Go内存优化的工作，总结了一些定位、调优方面的套路和经验，于是，想通过这篇文章与大家分享讨论。\n发现问题 性能优化领域有一条总所周知的铁律，即：不要过早地优化。编写一个程序，首先应该保证其功能的正确性，以及诸如设计是否合理、需求等是否满足，过早地优化只会引入不必要的复杂度以及设计不合理等各种问题。\n那么何时才能开始优化呢？一句话，问题出现时。诸如程序出现频繁OOM，CPU使用率异常偏高等情况。如今，在这微服务盛行的时代，公司内部都会拥有一套或简单或复杂的监控系统，当系统给你发出相关告警时，你就要开始重视起来了。\n问题定位 1. 查看内存曲线 首先，当程序发生OOM时，首先应该查看程序的内存使用量曲线，可以通过现有监控系统查看，或者prometheus之类的开源工具。\n曲线一般都是呈上升趋势，比如goroutine泄露的曲线一般是使用量缓慢上升直至OOM，而内存分配不合理往往时在高负载时快速攀升以致OOM。\n2. 问题复现 这块是可选项，但是最好能保证复现。如果能在本地或debug环境复现问题，这将非常有利于我们反复进行测试和验证。\n3. 使用pprof定位 Go官方工具提供了pporf来专门用以性能问题定位，首先得在程序中开启pprof收集功能，这里假定问题程序已开启pprof。(对这块不够了解的同学，建议通过这两篇文章(1, 2)学习下pprof工具的基本用法)\n接下来，我们复现问题场景，并及时获取heap和groutine的采样信息。\n 获取heap信息: curl http://loalhost:6060/debug/pprof/heap -o h1.out 获取groutine信息：curl http://loalhost:6060/debug/pprof/goroutine -o g1.out  这里你可能想问，这样就够了吗？\n当然不是，只获取一份样本信息是不够的。内存使用量是不断变化的(通常是上升)，因此我们需要的也是期间heap、gourtine信息的变化信息，而非瞬时值。一般来说，我们需要一份正常情况下的样本信息，一份或多份内存升高期间的样本信息。\n数据收集完毕后，我们按照如下3个方面来排查定位。\n排查goroutine泄露 使用命令go tool pprof --base g1.out g2.out ，比较goroutine信息来判断是否有goroutine激增的情况。\n进入交互界面后，输入top命令，查看期间goroutine的变化。\n同时可执行go tool pprof --base g2.out g3.out来验证。我之前写了的一篇实战文章，记录了goroutine泄露的排查过程。\n排查内存使用量 使用命令go tool pprof --base h1.out h2.out，比较当前堆内存的使用量信息来判断内存使用量。\n进入交互界面后，输入top命令，查看期间堆内存使用量的变化。\n排查内存分配量 当上述排查方向都没发现问题时，那就要查看期间是否有大量的内存申请了，以至于GC都来不及回收。使用命令go tool pprof --alloc_space --base h1.out h2.out，通过比较前后内存分配量来判断是否有分配不合理的现象。\n进入交互界面后，输入top命令，查看期间堆内存分配量的变化。\n一般来说，通过上述3个方面的排查，我们基本就能定位出究竟是哪方面的问题导致内存激增了。我们可以通过web命令，更为直观地查看问题函数(方法)的完整调用链。\n问题优化 定位到问题根因后，接下来就是优化阶段了。这个阶段需要对Go本身足够熟悉，还得对问题程序的业务逻辑有所了解。\n我梳理了一些常见的优化手段，仅供参考。实际场景还是得实际分析。\ngoroutine泄露 这种问题还是比较好修复的，需要显式地保证goroutine能正确退出，而非以一些自以为的假设来保证。例如，通过传递context.Context对象来显式退出\ngo func(ctx context.","title":"Golang内存优化实践指南"},{"content":"问题的发现 周五，本是一个风清气爽，令人愉悦的日子。我本还在美滋滋地等待着下班，然而天有不测，有用户反应容器日志看不到了，根据经验我知道，日志采集\u0026amp;收集链路上很可能又发生了阻塞。\n登录目标容器所在机器找到日志采集容器，并娴熟地敲下docker logs --tail 200 -f \u0026lt;container-id\u0026gt;命令，发现确实阻塞了，阻塞原因是上报日志的请求500了，从而不断重试导致日志采集阻塞。\n随后，我找到收集端的容器，查看日志，发现确实有请求报500了，并且抛出了Unknown value type的错误，查看相关代码。\n业务代码：\nif _, err := jsonparser.ArrayEach(body, func(value []byte, dataType jsonparser.ValueType, offset int, err error) {  ... }); err != nil {  return err // 错误抛出点 } jsonparser包中代码：\n显然问题出在了对body的解析上，究竟是什么样的body导致了解析错误呢？接下来，就是tcpdump和wireshark上场的时候了。\n使用Tcpdump抓包 首先，我们通过tcpdump抓到相关的请求。由于日志采集端会不断重试，因此最简单的方法便是登录采集端所在机器，并敲下如下命令tcpdump -i tunl0 dst port 7777 -w td.out ，并等待10-20秒。\n熟悉tcpdump的小伙伴，对这条命令显然已经心领神会了。尽管如此，这里我还是稍微解释下。\n -i tunl0：-i 参数用来指定网卡，由于采集器并没有通过eth0。因此，实战中，有时发现命令正确缺抓不到包的情况时，不妨指定下别的网卡。网络错综复杂，不一定都会通过eth0网卡。 dst port 777： 指定了目标端口作为过滤参数，收集端程序的端口号是7777 -w td.out: 表明将抓包记录保存在td.out文件中，这是因为json body是用base64编码并使用gzip加密后传输的，因此我得使用wireshark来抽离出来。（主要还是wireshark太香了:)，界面友好，操作简单，功能强大）  接着，我用scp命令将td.out文件拷到本地。并使用wireshar打开它\n使用Wireshark分析 打开后，首先映入眼帘的则是上图内容，看起来很多？不要慌，由于我们排查的是http请求，在过滤栏里输入HTTP，过滤掉非HTTP协议的记录。\n我们可以很清楚地发现，所有的HTTP都是发往一个IP的，且长度都是59，显然这些请求都是日志采集端程序不断重试的请求。接下来，我们只需要将某个请求里的body提取出来查看即可。\n很幸运，wireshark提供了这种功能，如上图所示，我们成功提取出来body内容。为bnVsbA==，使用base64解码后为null。\n解决问题 既然body的内容为null，那么调用jsonparser.ArrayEach报错也是意料之中的了，body内容必须得是一个JsonArray。\n然而，采集端为何会发送body为null的请求呢，深入源码，发现了如下一段逻辑。\nfunc (e *jsonEncoder) encode(obj []publisher.Event) (*bytes.Buffer, error) { \tvar events []map[string]interface{} \tfor _, o := range obj { \tm, err := transformMap(o) \tif err != nil { \tlogp.Err(\u0026#34;Fail to transform map with err: %s\u0026#34;, err) \tcontinue \t} \tevents = append(events, m) \t} \tdata, err := json.Marshal(events) \tif err != nil { \treturn nil, errors.Wrap(err, \u0026#34;fail to json marshal events\u0026#34;) \t}  ... } 由于transforMap函数回对obj中的元素进行转换，成功后添加到events中。\n但是，由于使用的是var events []map[string]interface{}这种声明方式，在Golang中，slice的零值为nil，因此events此时的值为nil。而当obj中所有的对象，被transforMap失败时，events使用json序列化后则为null了。\n这里我们需改变evetns的声明方式，使用events := make([]map[string]interface{}, 0)或者events := []map[string]interface{}{}的方式替代，此时events被初始化了，并指向的是一个cap为0的slice对象，其序列化后为[]。\n这样即使没有对象添加到events中，上报的也是一个空数组。\n参考  https://www.cnblogs.com/ggjucheng/archive/2012/01/14/2322659.html https://www.k0rz3n.com/2017/04/17/wireshark/  ","permalink":"https://erenming.github.io/posts/tcpdump-pricate-record/","summary":"问题的发现 周五，本是一个风清气爽，令人愉悦的日子。我本还在美滋滋地等待着下班，然而天有不测，有用户反应容器日志看不到了，根据经验我知道，日志采集\u0026amp;收集链路上很可能又发生了阻塞。\n登录目标容器所在机器找到日志采集容器，并娴熟地敲下docker logs --tail 200 -f \u0026lt;container-id\u0026gt;命令，发现确实阻塞了，阻塞原因是上报日志的请求500了，从而不断重试导致日志采集阻塞。\n随后，我找到收集端的容器，查看日志，发现确实有请求报500了，并且抛出了Unknown value type的错误，查看相关代码。\n业务代码：\nif _, err := jsonparser.ArrayEach(body, func(value []byte, dataType jsonparser.ValueType, offset int, err error) {  ... }); err != nil {  return err // 错误抛出点 } jsonparser包中代码：\n显然问题出在了对body的解析上，究竟是什么样的body导致了解析错误呢？接下来，就是tcpdump和wireshark上场的时候了。\n使用Tcpdump抓包 首先，我们通过tcpdump抓到相关的请求。由于日志采集端会不断重试，因此最简单的方法便是登录采集端所在机器，并敲下如下命令tcpdump -i tunl0 dst port 7777 -w td.out ，并等待10-20秒。\n熟悉tcpdump的小伙伴，对这条命令显然已经心领神会了。尽管如此，这里我还是稍微解释下。\n -i tunl0：-i 参数用来指定网卡，由于采集器并没有通过eth0。因此，实战中，有时发现命令正确缺抓不到包的情况时，不妨指定下别的网卡。网络错综复杂，不一定都会通过eth0网卡。 dst port 777： 指定了目标端口作为过滤参数，收集端程序的端口号是7777 -w td.out: 表明将抓包记录保存在td.out文件中，这是因为json body是用base64编码并使用gzip加密后传输的，因此我得使用wireshark来抽离出来。（主要还是wireshark太香了:)，界面友好，操作简单，功能强大）  接着，我用scp命令将td.out文件拷到本地。并使用wireshar打开它\n使用Wireshark分析 打开后，首先映入眼帘的则是上图内容，看起来很多？不要慌，由于我们排查的是http请求，在过滤栏里输入HTTP，过滤掉非HTTP协议的记录。\n我们可以很清楚地发现，所有的HTTP都是发往一个IP的，且长度都是59，显然这些请求都是日志采集端程序不断重试的请求。接下来，我们只需要将某个请求里的body提取出来查看即可。\n很幸运，wireshark提供了这种功能，如上图所示，我们成功提取出来body内容。为bnVsbA==，使用base64解码后为null。","title":"一次抓包排查实战记录"},{"content":"总所周知，大多数语言中，字典的底层是哈希表，而且其算法也是十分清晰的。无论采用链表法还是开放寻址法，我们都能实现一个简单的哈希表结构。对于Go来说，它是具体如何实现哈希表的呢？以及，采取了哪些优化策略呢？\n内存模型 map在内存的总体结构如下图所示。\n头部结构体hmap type hmap struct { \tcount int // 键值对个数 \tflags uint8 \tB uint8 // 2^B = 桶数量 \tnoverflow uint16 // 溢出桶的个数 \thash0 uint32 // hash seed  \tbuckets unsafe.Pointer // 哈希桶 \toldbuckets unsafe.Pointer // 原哈希桶，扩容时为非空 \tnevacuate uintptr // 扩容进度，地址小于它的桶已被迁移了  \textra *mapextra // optional fields } hmap即为map编译后的内存表示，这里需要注意的有两点。\n B的值是根据负载因子(LoadFactor)以及存储的键值对数量，在创建或扩容时动态改变 buckets是一个指针，它指向一个bmap结构  桶结构体bmap type bmap struct { \t// tophash数组可以看做键值对的索引 \ttophash [bucketCnt]uint8 \t// 实际上编译器会动态添加下述属性  // keys [8]keytype  // values [8]valuetype  // padding uinptr  // overflow uinptr } 虽然bmap结构体中只有一个tophash数组，但实际上，其后跟着8个key的槽位、8个value的槽位、padding以及一个overflow指针。如下图所示\n这里，Go做了优化。\n 这里并没有把key/value作为一个entry，而是分开存储。主要是为了节省内存，有时可以避免使用padding(额外的内存)来对齐，比如map[int64]int8就完全不需要padding。  查找操作 查找操作总体和链表法的哈希表查找类似，即key \u0026mdash;\u0026gt; hashFunc(key) \u0026mdash;\u0026gt; mask(hash) \u0026mdash;\u0026gt; 桶的位置 \u0026mdash;\u0026gt; 遍历链表。其主要代码如下所示\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { \t... \talg := t.key.alg \thash := alg.hash(key, uintptr(h.hash0)) \tm := bucketMask(h.B) \t// 计算得到桶的位置bucket-k \tb := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize)))  // 若正在扩容，老buckets则为非空 \t// 若bucket-k在老的buckets数组中，未被迁移，则使用老的 \tif c := h.oldbuckets; c != nil { \tif !h.sameSizeGrow() { \t// There used to be half as many buckets; mask down one more power of two. \tm \u0026gt;\u0026gt;= 1 \t} \toldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) \tif !evacuated(oldb) { \tb = oldb \t} \t} \t// 根据tophash(hash), 在bucket-k中的tophash中查找key \ttop := tophash(hash)  // 找到对应的bucket后，遍历查找对应的key/value bucketloop: \tfor ; b != nil; b = b.overflow(t) { \tfor i := uintptr(0); i \u0026lt; bucketCnt; i++ { \t... \t// 计算第i个位置的key的地址 \tk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) \tif t.indirectkey() { \tk = *((*unsafe.Pointer)(k)) \t} \t// 比较tophash[i]上的k是否与目标key相等 \tif alg.equal(key, k) {  // 计算value的地址 \tv := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) \tif t.indirectvalue() { \tv = *((*unsafe.Pointer)(v)) \t} \treturn v \t} \t} \t} \t// 若最终还是没找到，则返回nil \treturn unsafe.Pointer(\u0026amp;zeroVal[0]) } 首先，Go通过对应类型的alg.hash计算得到hash值（各种类型的hash\u0026amp;equal函数定义），取后B位作为buckets数组的下标(实际上为取余)，取高8位作为tophash的下标。\n然后，通过一个嵌套循环查找目标key：外层循环是遍历一个bmap单链表，它们通过overflow指针相连；内层循环则遍历tophash数组，逐个比较，当匹配成功时，则计算得到实际key的地址，比较两者，成功则返回。如下图所示\n这里，Go做了如下优化。\n 使用tophash数组，作为索引，用以判断key是否存在该bmap中，若确实存在，再使用较为耗时的比较算法判断key是否相等。  除了查找操作，map的插入、删除以及扩容操作也十分值得学习，大家可以去查阅相关源码\n本人才疏学浅，文章难免有些不足之处，非常欢迎大大们评论指出。\n参考  https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics#easy-footnote-1-3224 https://github.com/golang/go/blob/master/src/runtime/map.go https://studygolang.com/articles/25134 https://www.linkinstar.wiki/2019/06/03/golang/source-code/graphic-golang-map/ [https://github.com/qcrao/Go-Questions/blob/master/map/map%20%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88.md](https://github.com/qcrao/Go-Questions/blob/master/map/map 的底层实现原理是什么.md)  ","permalink":"https://erenming.github.io/posts/map-in-go/","summary":"总所周知，大多数语言中，字典的底层是哈希表，而且其算法也是十分清晰的。无论采用链表法还是开放寻址法，我们都能实现一个简单的哈希表结构。对于Go来说，它是具体如何实现哈希表的呢？以及，采取了哪些优化策略呢？\n内存模型 map在内存的总体结构如下图所示。\n头部结构体hmap type hmap struct { \tcount int // 键值对个数 \tflags uint8 \tB uint8 // 2^B = 桶数量 \tnoverflow uint16 // 溢出桶的个数 \thash0 uint32 // hash seed  \tbuckets unsafe.Pointer // 哈希桶 \toldbuckets unsafe.Pointer // 原哈希桶，扩容时为非空 \tnevacuate uintptr // 扩容进度，地址小于它的桶已被迁移了  \textra *mapextra // optional fields } hmap即为map编译后的内存表示，这里需要注意的有两点。\n B的值是根据负载因子(LoadFactor)以及存储的键值对数量，在创建或扩容时动态改变 buckets是一个指针，它指向一个bmap结构  桶结构体bmap type bmap struct { \t// tophash数组可以看做键值对的索引 \ttophash [bucketCnt]uint8 \t// 实际上编译器会动态添加下述属性  // keys [8]keytype  // values [8]valuetype  // padding uinptr  // overflow uinptr } 虽然bmap结构体中只有一个tophash数组，但实际上，其后跟着8个key的槽位、8个value的槽位、padding以及一个overflow指针。如下图所示","title":"Golang中的map实现"},{"content":"在编写web应用中，我们常常会遇到这样的需求，比如，我们需要上报每个API的运行时间到运维监控系统。这时候你可以像下述代码一样将统计的逻辑写到每个路由函数中。\nfunc someApi(w http.ResponseWriter, r *http.Request) { \tstart := time.Now() \t// your logic \tmetrics.Upload(time.Since(start)) } 然而，这显然有悖DRY原则，我们需要将这些非业务逻辑剥离出来以实现解耦。这时候，中间件就能派上用场了，为了简单起见，我们这里将采用标准库net/http来实现。\n准备工作 func hello(w http.ResponseWriter, r *http.Request) { \tlog.Println(\u0026#34;execute hello func\u0026#34;) \tw.Write([]byte(\u0026#34;hello, world\u0026#34;)) }  func main() { \thttp.Handle(\u0026#34;/\u0026#34;, http.HandlerFunc(hello)) \thttp.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) } 这里，我们创建了一个hello函数并将其转换成一个Handler用以处理HTTP请求。\n中间件的实现 func middlewareOne(next http.Handler) http.Handler { \treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { \tlog.Println(\u0026#34;middleware one start\u0026#34;) // before logic \tnext.ServeHTTP(w, r) \tlog.Println(\u0026#34;middleware one end\u0026#34;) // after logic \t}) } 这里，我们实现了一个中间件函数middlewareOne，它接收一个next的参数其类型为http.Handler并返回一个新的http.Handler。而next.ServeHTTP(w, r)会回调next函数自身，即next(w, r)。看到这里，你可能会有点懵，我们需要先复习一下Handler，HandlerFunc，ServeHTTP三者的关系。\n下面是三者的定义：\n// A Handler responds to an HTTP request. type Handler interface { \tServeHTTP(ResponseWriter, *Request) }  type HandlerFunc func(ResponseWriter, *Request)  // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { \tf(w, r) } Handler是一个接口，用以处理HTTP请求，换句话说，一个函数若想成为一个路由函数必须得是一个Handler接口。\nHandlerFunc是一个签名为func(ResponseWriter, *Request)的函数类型，其实现了ServerHTTP方法且签名相同，故HandleFunc是一个Handler，其ServerHTTP方法调用HandlerFunc自身。\n三者关系如下图所示：\n好了，接下来我们将中间件函数应用到我们的Handler上。\nfunc main() { \thttp.Handle(\u0026#34;/\u0026#34;, middlewareOne(http.HandlerFunc(hello))) \thttp.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) } 运行程序，然后访问http://127.0.0.1:3000/，控制台将输出如下结果。\n2019/12/middleware one start 2019/12/execute hello func 2019/12/middleware one end 当然，如果你想应用多个中间件，你只需要再套上一层，例如下述代码：\nfunc middlewareTwo(next http.Handler) http.Handler { \treturn http.HandlerFunc(func (w http.ResponseWriter, r *http.Request) { \tlog.Println(\u0026#34;middleware two start\u0026#34;) \tnext.ServeHTTP(w, r) \tlog.Println(\u0026#34;middleware two end\u0026#34;) \t}) }  func main() { \thttp.Handle(\u0026#34;/\u0026#34;, middlewareTwo(middlewareOne(http.HandlerFunc(hello)))) \thttp.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) } 我画出了该函数链的执行流程，如下图所示：\n可以看到，如果我们把路由函数hello看做为汉堡里的肉饼，中间件函数看做成面包。那么，middlewareOne包住了肉饼hello，而middlewareTwo又包住了middlewareTwo。\n总结  中间件函数与Python中的装饰器函数十分类似，都是在原函数逻辑不变的条件下进行扩展。 对于Web框架而言，类似于Flask里面的before_request和after_request钩子函数，next.ServeHTTP之前逻辑的等同于before_request里的逻辑、之后的等同于于after_request里的逻辑。 在业务开发中，我们应尽量将非业务逻辑抽象到中间件中，实现代码的松耦合与易扩展。  本人才疏学浅，文章难免有些不足之处，非常欢迎大家评论指出。\n参考  https://github.com/chai2010/advanced-go-programming-book/blob/master/ch5-web/ch5-03-middleware.md https://www.alexedwards.net/blog/making-and-using-middleware https://golang.org/doc/effective_go.html#interface_methods ","permalink":"https://erenming.github.io/posts/understand-middleware/","summary":"\u003cp\u003e在编写web应用中，我们常常会遇到这样的需求，比如，我们需要上报每个API的运行时间到运维监控系统。这时候你可以像下述代码一样将统计的逻辑写到每个路由函数中。\u003c/p\u003e","title":"用Golang实现并理解Web中间件"},{"content":"说到string类型，我们往往都能很熟练地对它进行各种处理，包括迭代、随机访问和匹配等等操作。然而在工作中，我发现迭代一个字符串产生的字符的类型与随机访问一个字符的类型却并不相同，为什么会这么奇怪呢？于是我决定一探究竟\nstring 简析 在Golang中，字符串本质上看一看做一个只读的字节切片(仅比切片少了一个Cap属性)。它的底层结构我们可以查看reflect.StringHeader得到:\ntype StringHeader struct {  Data uintptr  Len int } 例如针对字符串\u0026quot;你好\u0026quot;，其在内存中的表示如下图所示： Go的源文件默认使用UTF-8编码，所有的字符串字面量一般也是UTF-8编码的，故这里的你编码为\\xe4\\xbd\\xa0，好编码为\\xe5\\xa5\\xbd。UTF-8编码不是我们讨论的重点，具体可参考这篇博客。\n这里我们运行下述代码\n\ts := []byte{0xe4, 0xbd, 0xa0} \tfmt.Printf(\u0026#34;char is %s\u0026#34;, string(s)) 得到运行结果char is 你。\n虽然字符串并非切片，但是支持切片操作。对于同一字面量，不同的字符串变量指向相同的底层数组，这是因为字符串是只读的，为了节省内存，相同字面量的字符串通常对应于同一字符串常量。例如：\n\ts := \u0026#34;hello, world\u0026#34; \ts1 := \u0026#34;hello, world\u0026#34; \ts2 := \u0026#34;hello, world\u0026#34;[7:] \tfmt.Printf(\u0026#34;%d \\n\u0026#34;, (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)).Data) // 17598361 \tfmt.Printf(\u0026#34;%d \\n\u0026#34;, (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s1)).Data) // 17598361 \tfmt.Printf(\u0026#34;%d \\n\u0026#34;, (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s2)).Data) // 17598368 可以看到，三者均指向同一个底层数组。对于s1, s2由于是同一字符串常量hello, world，故指向一个底层数组，以h为起始位置；而s2是字面量hello, world的切片操作后生成的字符串，也指向同一字节底层数组，不过是以w为起始位置。\n迭代字符串 当我们使用for range迭代字符串时，每次迭代Go都会用UTF-8解码出一个rune类型的字符，且索引为当前rune的起始位置(以字节为最下单位)。\n\tfor index, char := range \u0026#34;你好\u0026#34; { \tfmt.Printf(\u0026#34;start at %d, Unicode = %U, char = %c\\n\u0026#34;, index, char, char) \t} 得到运行结果\nstart at 0, Unicode = U+4F60, char = 你 start at 3, Unicode = U+597D, char = 好 随机访问字符串 当我们用下标访问字符串时，返回的值为单个字节，而我们直觉中，应该返回一个字符才合理。这还是因为string的后端数组是一个字节切片而非一个字符切片\n\ts := \u0026#34;你好\u0026#34; \tfmt.Printf(\u0026#34;s[%d] = %q, hex = %x, Unicode = %U\u0026#34;, 1, s[1], s[1], s[1]) 得到运行结果\ns[1] = \u0026#39;½\u0026#39;, hex = bd, Unicode = U+00BD 这里我们打印出来索引位置为1的字节，为0xbd，其Unicode为U+00BD, 代表的字符为½。(你可以通过这里查询)\n到底什么是rune、字符和字节 字节：即byte，它由8个位组成，即1byte = 8bit，是计算机中的基本计量单位，在Go中为byte类型，其实际上为uint8的别名\n字符：字符的概念比较模糊，在Unicode中通常用code point来表示。在我的理解里，是一种信息单元(例如一个符号、字母等)\nrune：其实际上是int32的别名，但是为了方便将字符与整数值区分开，从而新增了rune类型代表一个字符。\n总结  通过下标访问字符串时，返回的是一个字节，这往往与我们的直觉相背。所以，如果你一定要通过下标访问字符串，可以先将其转换为[]rune类型 字符串可以看做是一个只读字节切片, 支持切片操作。  本人才疏学浅，文章难免有些不足之处，非常欢迎大家评论指出。\n参考  https://chorer.github.io/2019/09/16/CB-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9Fcp1/ https://draveness.me/golang/datastructure/golang-string.html https://berryjam.github.io/2018/03/%E4%BB%8Egolang%E5%AD%97%E7%AC%A6%E4%B8%B2string%E9%81%8D%E5%8E%86%E8%AF%B4%E8%B5%B7/ https://en.wikipedia.org/wiki/Code_point https://github.com/chai2010/advanced-go-programming-book/blob/master/ch1-basic/ch1-03-array-string-and-slice.md ","permalink":"https://erenming.github.io/posts/string-in-golang/","summary":"\u003cp\u003e说到\u003ccode\u003estring\u003c/code\u003e类型，我们往往都能很熟练地对它进行各种处理，包括迭代、随机访问和匹配等等操作。然而在工作中，我发现迭代一个字符串产生的字符的类型与随机访问一个字符的类型却并不相同，为什么会这么奇怪呢？于是我决定一探究竟\u003c/p\u003e","title":"Golang中的string实现"},{"content":"嗨，我的朋友！\n欢迎来到我的技术博客，我的名字叫姜小明（erenming)。我的座右铭是Keep it simple stupid，没错，就是大名鼎鼎的KISS原则。\n一名程序员，使用Go作为我的主要开发语言，目前专注于可观测性，云原生领域。\n最后，欢迎与我联系，一起探讨技术 :P\n","permalink":"https://erenming.github.io/about/","summary":"嗨，我的朋友！\n欢迎来到我的技术博客，我的名字叫姜小明（erenming)。我的座右铭是Keep it simple stupid，没错，就是大名鼎鼎的KISS原则。\n一名程序员，使用Go作为我的主要开发语言，目前专注于可观测性，云原生领域。\n最后，欢迎与我联系，一起探讨技术 :P","title":"About"},{"content":"仅以记录我在读、已读、预读之书。\n在读 22.06-22.12  《知识变现》：技术人还是看看，学习下如何提升影响力 《Observability Engineering》：关于可观测领域比较全面的书了，从业者可重点关注第1、2、4章节 《stop reading news》：这年头新闻确实太多，浪费时间且过度焦虑 《Systems Performance: Enterprise and the Cloud》：性能之巅第二版，得好好学学 《Dive into Refactoring》： 重构方面的书 《Queueing theory in Action》：排队理论，工作中队列的使用无处不在，需要学习下  预读  《Building Event Driven Microservice》 《Programming Rust》：学习下最先进的Rust吧  已读  《Real-Time Analytics Techniques to Analyze》：70%   介绍了流式系统的常见设计和考虑，还是不错的，对我设计监控数据链路有帮助\n  《Kubernetes In Action》：100%   挺不错的一本书，Kubernetes的东西基本都涵盖了，其中的各种流程图有助于理解各组件的工作机制\n  《Designing Data Intensive Applications》：200%   读了两遍，强烈推荐，尤其是第一部分和第二部分。读完之后, 能对现如今的各种分布式数据组件的有更深的理解，配合Mit-6.824食用更佳\n  《Computer.Systems.A.Programmers.Perspective.3rd.Global.Edition.2015.7-csapp》: 45%   主要看了CPU部分。以更为通俗易懂、诙谐的方式讲解操作系统，尤其是每章之后的教授问答环节。不过感觉还是作为教科书的目的编写的\n  《GO专家编程》：30%   华为大佬编写，主要对Go语言各种实现原理进行讲解。对实现能有大概的理解，不过也没有太深入细节，可以面试前看看。\n  《垃圾回收的算法与实现》：60%   介绍了各种GC算法和具体语言的实现，可以重点看看算法篇，对了解GC很有帮助，不过我当时还是看不太懂，可能需要再修炼修炼才能更好理解\n ","permalink":"https://erenming.github.io/readings/","summary":"仅以记录我在读、已读、预读之书。\n在读 22.06-22.12  《知识变现》：技术人还是看看，学习下如何提升影响力 《Observability Engineering》：关于可观测领域比较全面的书了，从业者可重点关注第1、2、4章节 《stop reading news》：这年头新闻确实太多，浪费时间且过度焦虑 《Systems Performance: Enterprise and the Cloud》：性能之巅第二版，得好好学学 《Dive into Refactoring》： 重构方面的书 《Queueing theory in Action》：排队理论，工作中队列的使用无处不在，需要学习下  预读  《Building Event Driven Microservice》 《Programming Rust》：学习下最先进的Rust吧  已读  《Real-Time Analytics Techniques to Analyze》：70%   介绍了流式系统的常见设计和考虑，还是不错的，对我设计监控数据链路有帮助\n  《Kubernetes In Action》：100%   挺不错的一本书，Kubernetes的东西基本都涵盖了，其中的各种流程图有助于理解各组件的工作机制\n  《Designing Data Intensive Applications》：200%   读了两遍，强烈推荐，尤其是第一部分和第二部分。读完之后, 能对现如今的各种分布式数据组件的有更深的理解，配合Mit-6.824食用更佳\n  《Computer.Systems.A.Programmers.Perspective.3rd.Global.Edition.2015.7-csapp》: 45%   主要看了CPU部分。以更为通俗易懂、诙谐的方式讲解操作系统，尤其是每章之后的教授问答环节。不过感觉还是作为教科书的目的编写的\n  《GO专家编程》：30%   华为大佬编写，主要对Go语言各种实现原理进行讲解。对实现能有大概的理解，不过也没有太深入细节，可以面试前看看。","title":"Readings"}]