[{"content":"不知为何，可观测性这个词突然就火起来，各个大厂都甚至纷纷成立可观测团队了。那么可观测性究竟是个啥呢？它凭什么能火起来呢？它与传统监控有什么区别呢，是否又是新瓶装旧酒？\n 说实话，虽然我很久之前就听说过可观测性这个词，不过一直持怀疑态度，认为不过是炒概念。直到最近，读了《Observability Engineering》这本书，让我打开新视界，可观测性并非空穴来风，其确实有它的价值，而且相当大。\n 什么是可观测性 可观测性(Observability)这个单词最开始是出现于数学领域，表示度量一个系统内部状态由其外部输出的信息中推断出来的程度。Wikipedia上的定义有点抽象，举个汽车的例子：\n 一辆汽车可以说是一个系统，当其外部输出信息只有油箱油量、当前车速时，我们能推断出车辆预计还能行驶多少公里 而当其外部输出信息还包括发动机温度、轮胎磨损程度时，我们还能推断出发动机和轮胎的工作情况是否需要维护，如果需要维护那么能行驶的距离显然会比之前预估的行驶举例少，显然此时这辆汽车的可观测性程度比之更高了  而对于一个软件系统，它所能暴露的外部信息常见的有指标、日志、链路追踪事件，显然我们可以通一些工具来分析它的外部信息从而推断系统的内部状态。因此这里，软件系统暴露的信息越详细，分析工具越强劲，内部状态就能推断地越准确与详细，那么该软件系统的可观测性就越好。\n不过，此时你可能有疑问：这些指标日志啥的不都是些的现成东西吗？那是不是可以说，本质上，传统意义的监控就是可观测性呢？这里的答案是否定的，且听我下文解释。\n与传统监控的区别 传统意义上的监控(Monitoring)是一种行为，这种行为分析系统的内部状态。而可观测性正如上文中描述的一样，是一种系统的性质，其他性质有健壮性、可测试性等\n在传统监控的场景下，我们收集、存储并分析指标数据。我们制作监控大盘并设置各种告警，当发生异常时，告警触发,收到告警后，我们根据告警的内容以及相关的监控图表，来推断出异常发生的原因，并由此做出相应的处理（或增加资源、或修复Bug）。\n但是这里有一个很大前提，就是告警策略必须预先设置，而如何设置又完全取决于经验与直觉。换句话说，通过监控我们只能检测一些已知的潜在风险，例如机器的负载、CPU使用率、磁盘使用率等。而对于一个未知或复杂的系统，当它发生异常时，我们往往只能束手无策，或者通过一些线索去猜测可能的原因并验证，如果猜错了那又得重复上述过程，非常的浪费时间。\n而在可观测性的场景下，系统中植入了各种各样的代码和工具，并提供了非常丰富的可观测的数据（metric, logs, traces等各种数据），通过这些数据并结合合适的工具，我们能够很快地排查出问题的根因所在。举个例子，同样是一个未知的系统，当发现某个接口很慢时，我们可以通过链路追踪工具找到瓶颈点，通过瓶颈点再分析当时的系统资源使用率，饱和度，负载情况以及应用日志等，从而很快地定位出根因（资源问题？代码问题？第三方服务问题？等等）\n流行的原因 近10年IT相关行业发生了天翻地覆的变化。IT技术也是日新月异，尤其是微服务架构、分布式以及云原生的高速发展，以及各种敏捷开发思想深入人心。\n如今的软件系统已经与10年前的大不相同了，复杂度、灵活度、变化度等都大幅提升。而由此带来的问题就是，系统稳定性保障变得越来越困难，尤其是问题根因的定位\n 例如，对于一些复杂问题，有时候花费数个月都无法定位，最后的选择往往都是推倒重来\n 因此单靠传统的监控已经无法满足当下软件系统的观测需求，传统监控只能解决那些\u0026quot;known unknown/known\u0026quot;类的问题，而无法应对\u0026quot;unknown unknown\u0026quot;类的问题，而这类问题在如今的架构下要多得多。\n Known unknown/known：指的是你熟悉的已知或未知的软件系统，这种系统可预测，因此我们可以预先设置各种告警\nUnknown unknown：指的是你不熟悉的未知系统，这种系统完全未知，只能通过可观测性工具来探测\n 三大支柱是可观测性吗 一说到可观测性，可能最先联想的就是“三大支柱(the three pillars)”，即logs, metrics以及traces（如下图所示）。很多人（包括我）经常以为它们就是所谓的可观测性，毕竟很多PAAS平台和厂商就是这么宣传的，但这并不完全正确。\n是的，没错，三大支柱确实是可观测性体系里不可或缺的条件。但这并不代表我暴露了这些数据，我的软件系统就具备了可观测性，同样也不能代表我收集分析了这些数据，我就实现了一个可观测性工具系统。\n首先，可观测性需要的数据并非只有这三者，它还可以是用户的反馈信息、系统profiling信息等各种统计、事件信息；其次暴露的数据的维度、基数以及数据间的关联度等等都会影响系统的可观测性；而一个可观测性工具的搭建除了收集这些统计、时间信息，还包括数据传输与处理，数据存储以及交互的易用性等，此外涉及到的数据隔离，容量规划，低成本且高性能等问题也是十分棘手的。\n不过，话虽如此，“三大支柱”虽不能等同于可观测性，但它们是你迈向可观测性的第一步:)\n总结 综上所述，如果你的应用非常简单，比如一个单体应用，那么传统监控也足够满足需求了。但是一旦切换为微服务架构，甚至完全云原生化的开发方式时，此时软件系统的复杂度就成指数级增加了，而此时可观测性就显得异常重要。\n相信你都经过，一个软件系统随着业务的发展会变得越来越复杂，到最后每个人都只能往上面堆功能，而对老代码甚至不敢改动一行，最终软件系统就会变成人们口中的“屎山”，而后面的人的唯一选择只能是推到重来。\n而如果可观测性一开始就在架构考虑中，那么无论我们的的系统变化多大，多复杂，我们都能对其了如指掌并快速定位问题根因，此外还能提前发现到系统架构的不合理之处并及时调整。\n参考   Observability Engineering\n  https://www.splunk.com/en_us/data-insider/what-is-observability.html\n  https://en.wikipedia.org/wiki/Observability\n  https://www.dynatrace.com/news/blog/what-is-observability-2/\n  ","permalink":"https://erenming.github.io/posts/what-is-observability/","summary":"不知为何，可观测性这个词突然就火起来，各个大厂都甚至纷纷成立可观测团队了。那么可观测性究竟是个啥呢？它凭什么能火起来呢？它与传统监控有什么区别呢，是否又是新瓶装旧酒？\n 说实话，虽然我很久之前就听说过可观测性这个词，不过一直持怀疑态度，认为不过是炒概念。直到最近，读了《Observability Engineering》这本书，让我打开新视界，可观测性并非空穴来风，其确实有它的价值，而且相当大。\n 什么是可观测性 可观测性(Observability)这个单词最开始是出现于数学领域，表示度量一个系统内部状态由其外部输出的信息中推断出来的程度。Wikipedia上的定义有点抽象，举个汽车的例子：\n 一辆汽车可以说是一个系统，当其外部输出信息只有油箱油量、当前车速时，我们能推断出车辆预计还能行驶多少公里 而当其外部输出信息还包括发动机温度、轮胎磨损程度时，我们还能推断出发动机和轮胎的工作情况是否需要维护，如果需要维护那么能行驶的距离显然会比之前预估的行驶举例少，显然此时这辆汽车的可观测性程度比之更高了  而对于一个软件系统，它所能暴露的外部信息常见的有指标、日志、链路追踪事件，显然我们可以通一些工具来分析它的外部信息从而推断系统的内部状态。因此这里，软件系统暴露的信息越详细，分析工具越强劲，内部状态就能推断地越准确与详细，那么该软件系统的可观测性就越好。\n不过，此时你可能有疑问：这些指标日志啥的不都是些的现成东西吗？那是不是可以说，本质上，传统意义的监控就是可观测性呢？这里的答案是否定的，且听我下文解释。\n与传统监控的区别 传统意义上的监控(Monitoring)是一种行为，这种行为分析系统的内部状态。而可观测性正如上文中描述的一样，是一种系统的性质，其他性质有健壮性、可测试性等\n在传统监控的场景下，我们收集、存储并分析指标数据。我们制作监控大盘并设置各种告警，当发生异常时，告警触发,收到告警后，我们根据告警的内容以及相关的监控图表，来推断出异常发生的原因，并由此做出相应的处理（或增加资源、或修复Bug）。\n但是这里有一个很大前提，就是告警策略必须预先设置，而如何设置又完全取决于经验与直觉。换句话说，通过监控我们只能检测一些已知的潜在风险，例如机器的负载、CPU使用率、磁盘使用率等。而对于一个未知或复杂的系统，当它发生异常时，我们往往只能束手无策，或者通过一些线索去猜测可能的原因并验证，如果猜错了那又得重复上述过程，非常的浪费时间。\n而在可观测性的场景下，系统中植入了各种各样的代码和工具，并提供了非常丰富的可观测的数据（metric, logs, traces等各种数据），通过这些数据并结合合适的工具，我们能够很快地排查出问题的根因所在。举个例子，同样是一个未知的系统，当发现某个接口很慢时，我们可以通过链路追踪工具找到瓶颈点，通过瓶颈点再分析当时的系统资源使用率，饱和度，负载情况以及应用日志等，从而很快地定位出根因（资源问题？代码问题？第三方服务问题？等等）\n流行的原因 近10年IT相关行业发生了天翻地覆的变化。IT技术也是日新月异，尤其是微服务架构、分布式以及云原生的高速发展，以及各种敏捷开发思想深入人心。\n如今的软件系统已经与10年前的大不相同了，复杂度、灵活度、变化度等都大幅提升。而由此带来的问题就是，系统稳定性保障变得越来越困难，尤其是问题根因的定位\n 例如，对于一些复杂问题，有时候花费数个月都无法定位，最后的选择往往都是推倒重来\n 因此单靠传统的监控已经无法满足当下软件系统的观测需求，传统监控只能解决那些\u0026quot;known unknown/known\u0026quot;类的问题，而无法应对\u0026quot;unknown unknown\u0026quot;类的问题，而这类问题在如今的架构下要多得多。\n Known unknown/known：指的是你熟悉的已知或未知的软件系统，这种系统可预测，因此我们可以预先设置各种告警\nUnknown unknown：指的是你不熟悉的未知系统，这种系统完全未知，只能通过可观测性工具来探测\n 三大支柱是可观测性吗 一说到可观测性，可能最先联想的就是“三大支柱(the three pillars)”，即logs, metrics以及traces（如下图所示）。很多人（包括我）经常以为它们就是所谓的可观测性，毕竟很多PAAS平台和厂商就是这么宣传的，但这并不完全正确。\n是的，没错，三大支柱确实是可观测性体系里不可或缺的条件。但这并不代表我暴露了这些数据，我的软件系统就具备了可观测性，同样也不能代表我收集分析了这些数据，我就实现了一个可观测性工具系统。\n首先，可观测性需要的数据并非只有这三者，它还可以是用户的反馈信息、系统profiling信息等各种统计、事件信息；其次暴露的数据的维度、基数以及数据间的关联度等等都会影响系统的可观测性；而一个可观测性工具的搭建除了收集这些统计、时间信息，还包括数据传输与处理，数据存储以及交互的易用性等，此外涉及到的数据隔离，容量规划，低成本且高性能等问题也是十分棘手的。\n不过，话虽如此，“三大支柱”虽不能等同于可观测性，但它们是你迈向可观测性的第一步:)\n总结 综上所述，如果你的应用非常简单，比如一个单体应用，那么传统监控也足够满足需求了。但是一旦切换为微服务架构，甚至完全云原生化的开发方式时，此时软件系统的复杂度就成指数级增加了，而此时可观测性就显得异常重要。\n相信你都经过，一个软件系统随着业务的发展会变得越来越复杂，到最后每个人都只能往上面堆功能，而对老代码甚至不敢改动一行，最终软件系统就会变成人们口中的“屎山”，而后面的人的唯一选择只能是推到重来。\n而如果可观测性一开始就在架构考虑中，那么无论我们的的系统变化多大，多复杂，我们都能对其了如指掌并快速定位问题根因，此外还能提前发现到系统架构的不合理之处并及时调整。\n参考   Observability Engineering\n  https://www.splunk.com/en_us/data-insider/what-is-observability.html\n  https://en.wikipedia.org/wiki/Observability\n  https://www.dynatrace.com/news/blog/what-is-observability-2/\n  ","title":"聊一聊可观测性"},{"content":"问个问题，如何优化一条SQL语句？我们首先想到的肯定是建索引。对于ClickHouse也不例外，尤其是稀疏主键索引（类似传统数据库中的主键索引）对性能的影响非常大。在下文中，我将结合例子对稀疏主键索引进行详细解读。\n 注：本文内容主要参考官方文档，如果有余力，强烈建议先行阅读\n 数据准备 这里，我将就我比较熟悉的时序数据进行举例。首先通过如下SQL建表：\n-- create dabase create database test; use test; -- create table CREATE TABLE cpu ( `hostname` String, `reginon` String, `datacenter` String, `timestamp` DateTime64(9,\u0026#39;Asia/Shanghai\u0026#39;) CODEC (DoubleDelta), `usage_user` Float64, `usage_system` Float64 ) ENGINE = MergeTree() PRIMARY KEY tuple(); optimize table cpu_ts final ; 并将本地的样本数据导入：\ncat example/output.csv |clickhouse-client -d test -q \u0026#39;INSERT into cpu FORMAT CSV\u0026#39;    output.csv是时序数据样本，时间间隔为1秒，包含了从2022-01-01 08:00:00到2022-01-15 07:59:59一共1209600条记录\n  optimize table 会强制进行merge之类的操作，使其达到最终状态\n   查询某段时间范围内的CPU使用率 SQL如下:\nselect ts, avg(usage_user) from cpu where timestamp \u0026gt; \u0026#39;2022-01-15 06:59:59.000000000\u0026#39; and timestamp \u0026lt; \u0026#39;2022-01-15 07:59:59.000000000\u0026#39; group by toStartOfMinute(timestamp) as ts order by ts; 统计结果如下：\n60 rows in set. Elapsed: 0.025 sec. Processed 1.21 million rows, 9.72 MB (48.68 million rows/s., 391.19 MB/s.)  注意：clickhouse客户端对每次查询会给出简要的性能数据，便于用户进行简单分析\n 可以看到，尽管我们只查询了一个小时范围内的数据，但是依然扫描121万行数据，也就是进行了一次全表扫描！\n显然，这样的是不够的，我们需要建立合理的稀疏索引，而它将显著提高查询性能。\n稀疏主键索引 稀疏主键索引(Sparse Primary Indexes)，以下简称稀疏索引。其功能上类似于MySQL中的主键索引，不过实现原理上是截然不同的。\n长话短说，如若建立类似于B+树那种面向具体行的索引，在面对大数据场景时，必将占用大量内存和磁盘并且严重影响写入性能。此外，基于ClickHouse的实际使用场景考虑，也无需精确定位到每一行。\n因此，其总体设计上，ClickHouse将数据块按组（粒度）划分，并通过下标（mark）标记。这种设计使得索引的内存占用足够小，同时仍能显著提高查询性能，尤其是OLAP场景下的大数据量的范围查询和数据分析。\n配置Primary Key 稀疏索引可通过PRIMARY KEY语法指定，接下来让我们通过它来优化示例中的cpu表吧:\n-- create table with timestamp as primary key CREATE TABLE cpu_ts ( `hostname` String, `reginon` String, `datacenter` String, `timestamp` DateTime64(9,\u0026#39;Asia/Shanghai\u0026#39;) CODEC (DoubleDelta), `usage_user` Float64, `usage_system` Float64 ) ENGINE = MergeTree() PRIMARY KEY (timestamp) ORDER BY (timestamp, hostname); -- insert data from cpu insert into cpu_ts select * from cpu; optimize table cpu_ts final ; 执行相同的分析SQL：\nselect ts, avg(usage_user) from cpu_ts where timestamp \u0026gt; \u0026#39;2022-01-15 06:59:59.000000000\u0026#39; and timestamp \u0026lt; \u0026#39;2022-01-15 07:59:59.000000000\u0026#39; group by toStartOfMinute(timestamp) as ts order by ts; 输出如下：\n60 rows in set. Elapsed: 0.004 sec. Processed 12.29 thousand rows, 196.58 KB (3.21 million rows/s., 51.31 MB/s.) 可以看到同样的结果，仅扫描5千多行! 下面，让我们通过EXPALIN来分析：\nEXPLAIN indexes = 1 select ts, avg(usage_user) from cpu_ts where timestamp \u0026gt; \u0026#39;2022-01-15 06:59:59.000000000\u0026#39; and timestamp \u0026lt; \u0026#39;2022-01-15 07:59:59.000000000\u0026#39; group by toStartOfMinute(timestamp) as ts order by ts; 输出如下：\n┌─explain────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐ │ Expression (Projection) │ │ MergingSorted (Merge sorted streams for ORDER BY) │ │ MergeSorting (Merge sorted blocks for ORDER BY) │ │ PartialSorting (Sort each block for ORDER BY) │ │ Expression (Before ORDER BY) │ │ Aggregating │ │ Expression (Before GROUP BY) │ │ Filter (WHERE) │ │ SettingQuotaAndLimits (Set limits and quota after reading from storage) │ │ ReadFromMergeTree │ │ Indexes: │ │ PrimaryKey │ │ Keys: │ │ timestamp │ │ Condition: and((timestamp in (-inf, \u0026#39;1642204799.000000000\u0026#39;)), (timestamp in (\u0026#39;1642201199.000000000\u0026#39;, +inf))) │ │ Parts: 1/1 │ │ Granules: 1/148 │ └────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘ 17 rows in set. Elapsed: 0.003 sec. 可以看到，借助主键索引，我们仅仅扫描了一个粒度的数据，优化效果十分明显 ！\n实现原理 数据排布 我们不妨从实际磁盘上的数据文件来对ClickHouse有个总体上的理解。首先，让我们来看下cpu_ts表的某个partall_1_1_0/在磁盘上的存储结构：\n all_1_1_0其结构表示为： {分区}_{最小block数}_{最大block数}_{表示经历了几次merge}\n -rw-r----- 1 clickhouse clickhouse 589 Jun 26 05:42 checksums.txt -rw-r----- 1 clickhouse clickhouse 179 Jun 26 05:42 columns.txt -rw-r----- 1 clickhouse clickhouse 7 Jun 26 05:42 count.txt -rw-r----- 1 clickhouse clickhouse 55K Jun 26 05:42 datacenter.bin -rw-r----- 1 clickhouse clickhouse 3.4K Jun 26 05:42 datacenter.mrk2 -rw-r----- 1 clickhouse clickhouse 10 Jun 26 05:42 default_compression_codec.txt -rw-r----- 1 clickhouse clickhouse 34K Jun 26 05:42 hostname.bin -rw-r----- 1 clickhouse clickhouse 3.4K Jun 26 05:42 hostname.mrk2 -rw-r----- 1 clickhouse clickhouse 1.2K Jun 26 05:42 primary.idx -rw-r----- 1 clickhouse clickhouse 51K Jun 26 05:42 reginon.bin -rw-r----- 1 clickhouse clickhouse 3.4K Jun 26 05:42 reginon.mrk2 -rw-r----- 1 clickhouse clickhouse 147K Jun 26 05:42 timestamp.bin -rw-r----- 1 clickhouse clickhouse 3.4K Jun 26 05:42 timestamp.mrk2 -rw-r----- 1 clickhouse clickhouse 2.5M Jun 26 05:42 usage_system.bin -rw-r----- 1 clickhouse clickhouse 3.4K Jun 26 05:42 usage_system.mrk2 -rw-r----- 1 clickhouse clickhouse 2.5M Jun 26 05:42 usage_user.bin -rw-r----- 1 clickhouse clickhouse 3.4K Jun 26 05:42 usage_user.mrk2 其中主要文件如下:\n *.bin：每个表中的列上的值压缩后的数据文件 column.txt：此表中所有列以及每列的类型 default_compression_codec.txt：数据文件默认的压缩算法 primary.idx：数据索引，后文详解 *.mrk2：数据标记，后文详解 count.txt：此part中数据的行数   注意：通过指定的PRIMARY KEY，其数据行会以timestamp升序排列并生成主键索引，对于timestamp相同的行按照ORDER BY中的hostname进行(若PRIMARY KEY和ORDER BY分别指定，则PRIMARY KEY必须是ORDER BY的前缀)。\n 索引建立 上文提到ClickHouse会对数据进行分组，其中某一列内的值自然也是按照组(粒度，默认8192行)进行划分的。粒度，可以简单理解为ClickHouse中一组不可划分的最小数据单元。\n当处理数据时，ClickHouse会读取整个粒度内的所有数据，而不是一行一行地读取（批处理的思想无处不在哈）。因此对于cpu_ts表内的数据，会被划分为148个组(ceil(1210000/8192=148)，其整体数据排布如下所示：\n从上图可以看出，表内数据被按照每8192行划分为148个粒度，每个组内取PRIMARY KEY中指定列的最小数据作为数据，并通过标记给其编号，存储在primary.idx中（可以将其理解为一个数组，标记就是下标）。我们使用od命令od -l -j 0 -N 32 primary.idx将primary.idx打印出来：\n0000000 1640995200000000000 1641003392000000000 0000020 1641011584000000000 1641019776000000000 # 粒度数组：[1640995200000000000, 1641003392000000000, 1641011584000000000, 1641019776000000000]  (1642151554000000000-1642143362000000000)/1000000000 = 8192\n 当我们根据timestamp字段进行过滤时，ClickHouse会通过二分搜索算法对primary.txt中的timestamp列进行搜索，找到对应的组标记，从而实现快速定位。例如对于示例查询语句，ClickHouse定位到的标记是148，那么又要如何通过标记反向找到实际的数据块呢？\n数据定位 这里，ClickHouse是通过引入{column_name}.mrk文件来解决的，mrk文件存储了粒度编号与压缩前后数据的偏移量(offset)，其大致结构如下图所示：\n使用od命令od -l -j 0 -N 24 timestamp.mrk2输出如下：\n0000000 0 0 0000020 8192 1071 0000040 0 8192  # (0, 0, 8192)为一组，表示压缩后偏移量为0，压缩前偏移量为0，粒度内一共8192行 # (1071, 0, 8192)为一组，表示压缩后偏移量为1071， 压缩前偏移量为0，粒度内一共8192行 在前文中，我们已经通过primary.idx已经拿到了具体的粒度编号(mark)，接着我们通过编号在{column}.mrk中找到对应的数据压缩前后的偏移量。然后通过以下2个步骤将数据发送给分析引擎：\n 通过压缩后的偏移量定位到数据文件(*.bin)中的数据块并解压后加载到内存中 根据压缩前的偏移量定位到内存中相关未压缩的数据块，然后将其发送到分析引擎  总结 综上所述，ClickHouse的稀疏索引是综合权衡之下的产物，尽管其使用了一种看起来比较粗粒度的索引机制，但依然能获得达到相当客观的性能提升。毕竟默认8192行的粒度，对于动辄上亿级别的OLAP场景来说已经算是比较细粒度的了，同时得益于ClickHouse强大的并行计算与分析能力，其查询的性能需求是能够满足的。\n不过实际的使用场景中，由于PRIMARY KEY一旦定义就没法更改了，而实际的查询方式又往往是变化无常的。因此单靠稀疏索引有时无法满足实际需求。\nClickHouse为此额外提供了两种方案：一种是通过定义新的PRIMARY KEY，并通过创建新表或物化表之类来重建；而另外一种则是类似传统二级索引的机制叫做跳数索引来处理，这些我将在后序文章中进行介绍:)\n参考  https://github.com/timescale/tsbs https://clickhouse.com/docs/en/guides/improving-query-performance https://zhuanlan.zhihu.com/p/397411559 https://stackoverflow.com/questions/65198241/whats-the-process-of-clickhouse-primary-index  ","permalink":"https://erenming.github.io/posts/clickhouse-sparse-index/","summary":"问个问题，如何优化一条SQL语句？我们首先想到的肯定是建索引。对于ClickHouse也不例外，尤其是稀疏主键索引（类似传统数据库中的主键索引）对性能的影响非常大。在下文中，我将结合例子对稀疏主键索引进行详细解读。\n 注：本文内容主要参考官方文档，如果有余力，强烈建议先行阅读\n 数据准备 这里，我将就我比较熟悉的时序数据进行举例。首先通过如下SQL建表：\n-- create dabase create database test; use test; -- create table CREATE TABLE cpu ( `hostname` String, `reginon` String, `datacenter` String, `timestamp` DateTime64(9,\u0026#39;Asia/Shanghai\u0026#39;) CODEC (DoubleDelta), `usage_user` Float64, `usage_system` Float64 ) ENGINE = MergeTree() PRIMARY KEY tuple(); optimize table cpu_ts final ; 并将本地的样本数据导入：\ncat example/output.csv |clickhouse-client -d test -q \u0026#39;INSERT into cpu FORMAT CSV\u0026#39;    output.csv是时序数据样本，时间间隔为1秒，包含了从2022-01-01 08:00:00到2022-01-15 07:59:59一共1209600条记录\n  optimize table 会强制进行merge之类的操作，使其达到最终状态","title":"ClickHouse稀疏索引原理解读"},{"content":"记录一下使用Hugo生成静态博客，并通过githubPages自动化部署的过程。\n这里，我的目标是：\n 使用blog-source作为原始的内容仓库，\u0026lt;your-name\u0026gt;.github.io作为实际的githubPages仓库 通过github Action将两者串联起来，原始内容提交变更时，自动触发内容生成并发布  这样的好处是，可以将blog-source作为私有仓库，并能直接以\u0026lt;your-name\u0026gt;.github.io作为URL。且通过github action实现CICD，解放双手实现自动化。这里我画了一张图，便于理解：\nHugo 安装Hugo，然后初始化\n# macOS install hugo brew install hugo  # create site project hugo new site blog-source 选择你中意的主题并安装\ncd blog-source git init  # add paperMod as theme git submodule add https://github.com/adityatelange/hugo-PaperMod themes/paperMod 添加文章并启动demo\nhugo new posts/my-first-post.md # start demo for preview hugo server -D 创建一个额外的仓库，这里我创建一个名为blog-source的仓库并作为刚才创建的blog-source的远端仓库\ncd blog-source git init git remote add origin \u0026lt;your-remove-git\u0026gt; GithubPages 创建一个githubPages仓库，名称必须是\u0026lt;your-name\u0026gt;.github.io。DOC\nConnection 创建sshKey: ssh-keygen -t rsa -b 4096 -C \u0026quot;$(git config user.email)\u0026quot; -f gh-pages -N \u0026quot;\u0026quot;\n将私钥gh-pages内容复制，并在blog-source仓库的Settings-\u0026gt;Secrets-\u0026gt;Actions创建secret变量\n将公钥gh-pages.pub内容复制，并作为\u0026lt;your-name\u0026gt;.github.io的Deploy Key，记得勾选读写权限\n创建github workflow文件.github/workflows/gh-pages.yml，其内容如下所示：\nname: github pages  on:  push:  branches:  - master  # Set a branch to deploy, my branch is master  pull_request:  jobs:  deploy:  runs-on: ubuntu-20.04  steps:  - uses: actions/checkout@v2  with:  submodules: true # Fetch Hugo themes (true OR recursive)  fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod   - name: Setup Hugo  uses: peaceiris/actions-hugo@v2  with:  hugo-version: \u0026#39;0.99.1\u0026#39;  # extended: true   - name: Build  run: hugo --minify   - name: Deploy  uses: peaceiris/actions-gh-pages@v3  with:  external_repository: \u0026lt;your-name\u0026gt;/\u0026lt;your-name\u0026gt;.github.io  publish_branch: master  # the secret key  deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }}  publish_dir: ./public 完成后，在blog-source仓库提交代码并push即可触发workflow，可在仓库的Actions功能项下查看运行情况。\n若无意外，稍等片刻(估计是因为Github同步并非完全实时)，即可通过\u0026lt;your-name\u0026gt;/\u0026lt;your-name\u0026gt;.github.io访问博客了\n总结 综上所述，使用hugo生成静态网站，创建githubPages项目其实并不难，主要难点在于如何通过githubAction将两者链接起来，实现CICD。遇到问题，建议多多翻阅官方文档，一定是能解决的。\n参考  https://github.com/peaceiris/actions-gh-pages https://docs.github.com/en/pages/getting-started-with-github-pages/about-github-pages https://gohugo.io/hosting-and-deployment/hosting-on-github/  ","permalink":"https://erenming.github.io/posts/hugo-with-githubpages/","summary":"记录一下使用Hugo生成静态博客，并通过githubPages自动化部署的过程。\n这里，我的目标是：\n 使用blog-source作为原始的内容仓库，\u0026lt;your-name\u0026gt;.github.io作为实际的githubPages仓库 通过github Action将两者串联起来，原始内容提交变更时，自动触发内容生成并发布  这样的好处是，可以将blog-source作为私有仓库，并能直接以\u0026lt;your-name\u0026gt;.github.io作为URL。且通过github action实现CICD，解放双手实现自动化。这里我画了一张图，便于理解：\nHugo 安装Hugo，然后初始化\n# macOS install hugo brew install hugo  # create site project hugo new site blog-source 选择你中意的主题并安装\ncd blog-source git init  # add paperMod as theme git submodule add https://github.com/adityatelange/hugo-PaperMod themes/paperMod 添加文章并启动demo\nhugo new posts/my-first-post.md # start demo for preview hugo server -D 创建一个额外的仓库，这里我创建一个名为blog-source的仓库并作为刚才创建的blog-source的远端仓库\ncd blog-source git init git remote add origin \u0026lt;your-remove-git\u0026gt; GithubPages 创建一个githubPages仓库，名称必须是\u0026lt;your-name\u0026gt;.github.io。DOC\nConnection 创建sshKey: ssh-keygen -t rsa -b 4096 -C \u0026quot;$(git config user.","title":"使用Hugo部署GithubPages"},{"content":"不知为何，写博客总是断断续续，距离上次更新已过去快一年了，直至如今面试碰壁方才后悔莫及。\n事实上，写博客对于对于知识的小伙理解非常有好处，毕竟要让别人听得懂，首先自己得更懂才行嘛。因为，通常学习一项新知识，通常需要理论学习-实践-总结输出三个阶段，而我往往只完成了第一阶段便草草了事，无法对知识有更深入的理解。因此，我打算重启我的博客之路，持续学习持续输出。\n之前博客用过Hexo，也用过博客园等等，最近看到hugo的paperMod主题非常讨喜，因此打算彻底切换到hugo+paperMod，也算起个好头吧。之前的文章也会从博客园迁移到hugo上，不过后续两边也会尽量同步更新。\n然后，也打算支持中英文双语，主要是为了提升自己的英文水平，以便能和世界上的程序员更好地交流。不过目前主打还是中文，母语写起来还是方便点，英文会挑选文章进行编写翻译，同时英文文章也会同步发布在Medium上。\n此外，为了降低断更的概率、提高文章质量，我在这里给自己立一个flag，即每月至少更新一篇文章，文章长度适宜、做到通俗易懂、绝不模棱两可故作高深\n","permalink":"https://erenming.github.io/posts/restart-my-blog/","summary":"不知为何，写博客总是断断续续，距离上次更新已过去快一年了，直至如今面试碰壁方才后悔莫及。\n事实上，写博客对于对于知识的小伙理解非常有好处，毕竟要让别人听得懂，首先自己得更懂才行嘛。因为，通常学习一项新知识，通常需要理论学习-实践-总结输出三个阶段，而我往往只完成了第一阶段便草草了事，无法对知识有更深入的理解。因此，我打算重启我的博客之路，持续学习持续输出。\n之前博客用过Hexo，也用过博客园等等，最近看到hugo的paperMod主题非常讨喜，因此打算彻底切换到hugo+paperMod，也算起个好头吧。之前的文章也会从博客园迁移到hugo上，不过后续两边也会尽量同步更新。\n然后，也打算支持中英文双语，主要是为了提升自己的英文水平，以便能和世界上的程序员更好地交流。不过目前主打还是中文，母语写起来还是方便点，英文会挑选文章进行编写翻译，同时英文文章也会同步发布在Medium上。\n此外，为了降低断更的概率、提高文章质量，我在这里给自己立一个flag，即每月至少更新一篇文章，文章长度适宜、做到通俗易懂、绝不模棱两可故作高深","title":"重启博客之路"},{"content":"为什么需要内存分配器？ 总说周知，内存作为一种相对稀缺的资源，在操作系统中以虚拟内存的形式来作为一种内存抽象提供给进程，这里可以简单地把它看做一个连续的地址集合{0, 1, 2, ..., M}，由栈空间、堆空间、代码片、数据片等地址空间段组合而成，如下图所示(出自CS:APP3e, Bryant and O\u0026rsquo;Hallaron的第9章第9节)\n这里我们重点关注Heap（堆），堆是一块动态的虚拟内存地址空间。在C语言中，我们通常使用malloc来申请内存以及使用free来释放内存，也许你想问，这样不就足够了吗？但是，这种手动的内存管理会带来很多问题，比如：\n 给程序员带来额外的心智负担，必须得及时释放掉不再使用的内存空间，否则就很容易出现内存泄露 随着内存的不断申请与释放，会产生大量的内存碎片，这将大大降低内存的利用率  因此，正确高效地管理内存空间是非常有必要的，常见的技术实现有Sequential allocation, Free-List allocation等。那么，在Go中，内存是如何被管理的呢？\n 注：此为Go1.13.6的实现逻辑，随版本更替某些细节会有些许不同\n 实现原理 Go的内存分配器是基于TCMalloc设计的，因此我建议你先行查阅，这将有利于理解接下来的内容。\n大量工程经验证明，程序中的小对象占了绝大部分，且生命周期都较为短暂。因此，Go将内存划分为各种类别(Class)，并各自形成Free-List。相较于单一的Free-List分配器，分类后主要有以下优点：\n  其一方面减少不必要的搜索时间，因为对象只需要在其所属类别的空闲链表中搜索即可\n  另一方面减少了内存碎片化，同一类别的空闲链表，每个对象分配的空间都是一样大小(不足则补齐)，因此该链表除非无空闲空间，否则总能分配空间，避免了内存碎片\n  那么，Go内存分配器具体是如何实现的呢？接下来，我将以自顶向下的方式，从宏观到微观，层层拨开她的神秘面纱。\n数据结构 首先，介绍Go内存分配中相关的数据结构。其总体概览图如下所示：\nheapArena 在操作系统中，我们一般把堆看做是一块连续的虚拟内存空间。\nGo将其划分为数个相同大小的连续空间块，称之arena，其中，heapArena则作为arena空间的管理单元，其结构如下所示：\ntype heapArena struct {  bitmap [heapArenaBitmapBytes]byte  spans [pagesPerArena]*mspan  ... }  bitmap: 表示arena区域中的哪些地址保存了对象，哪些地址保存了指针 spans: 表示arena区域中的哪些操作系统页(8K)属于哪些mspan  mheap 然后，则是核心角色mheap了，它是Go内存管理中的核心数据结构，作为全局唯一变量，其结构如下所示：\ntype mheap struct { \tfree mTreap  ...  allspans []*mspan  ...  arenas [1 \u0026lt;\u0026lt; arenaL1Bits]*[1 \u0026lt;\u0026lt; arenaL2Bits]*heapArena  ...  central [numSpanClasses]struct { \tmcentral mcentral \tpad [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte \t} }  free: 使用树堆的结构来保存各种类别的空闲mspan allspans: 用以记录了分配过了的mspan arenas: 表示其覆盖的所有arena区域，通过虚拟内存地址计算得到下标索引 central: 表示其覆盖的所有mcentral，一共134个，对应67个类别  mcentral 而mcentral充当mspan的中心管理员，负责管理某一类别的mspan，其结构如下：\ntype mcentral struct { \tlock mutex \tspanclass spanClass \tnonempty mSpanList \tempty mSpanList }  lock: 全局互斥锁，因为多个线程会并发请求 spanclass：mspan类别 nonempty：mspan的双端链表，且其中至少有一个mspan包含空闲对象 empty：mspan的双端链表，但不确定其中的mspan是否包含空闲对象  mcache mcache充当mspan的线程本地缓存角色，其与线程处理器(P)一一绑定。\n这样呢，当mcache有空闲mspan时，则无需向mcentral申请，因此可以避免诸多不必要的锁消耗。结构如下所示：\ntype mcache struct {  ...  alloc [numSpanClasses]*mspan  ... }  alloc: 表示各个类别的mspan  mspan mspan作为虚拟内存的实际管理单元，管理着一片内存空间(npages个页)，其结构如下所示：\ntype mspan struct { \tnext *mspan // 指向下一个mspan \tprev *mspan // 指向前一个mspan  ... \tnpages uintptr  freeindex uintptr  nelems uintptr // 总对象个数  ...  allocBits *gcBits \tgcmarkBits *gcBits }  next指针指向下一个mspan，prev指针指向前一个mspan，因此各个mspan彼此之间形成一个双端链表，并被runtime.mSpanList作为链表头。 npages：mspan所管理的页的数量 freeindex：空闲对象的起始位置，如果freeindex等于nelems时，则代表此mspan无空闲对象可分配了 allocBits：标记哪些元素已分配，哪些未分配。与freeindex结合，可跳过已分配的对象 gcmarkBits：标记哪些对象存活，每次GC结束时，将其设为allocBits  通过上述对Go内存管理中各个关键数据结构的介绍，想必现在，我们已经对其有了一个大概的轮廓。接下来，让我们继续探究，看看Go具体是如何利用这些数据结构来实现高效的内存分配算法\n算法 分配内存 内存分配算法，其主要函数为runtime.mallocgc，其基本步骤简述如下：\n 判断待分配对象的大小 若对象小于maxTinySize（16B），且不为指针，则执行微对象分配算法 若对象小于maxSmallSize（32KB），则执行小对象分配算法 否则，则执行大对象分配算法  在微对象以及小对象分配过程中，如果span中找不到足够的空闲空间，Go会触发层级的内存分配申请策略。其基本步骤如下：\n 先从mcache寻找对应类别的span，若有空闲对象，则成功返回 若无，则向mcentral申请，分别从nonempty和empty中寻找匹配的span，若找到，则成功返回 若还未找到，则继续向mheap申请，从mheap.free中寻找，若找到，则成功返回 若未找到，则需扩容，从关联的arena中申请，若关联的arena中空间也不足，则向OS申请额外的arena 扩容完毕后，继续从mheap.free中寻找，若仍未找到，则抛出错误  学到了什么  本地线程缓存，提高性能：通过mcache缓存小对象的span，并优先在mcache中分配，降低锁竞争 无处不在的BitMap应用场景：通过二进制位来映射对象，例如mspan.allocBits用以表示对象是否分配 多级分配策略：自底向上，性能损耗：低-\u0026gt;高，频率：高-\u0026gt;低，能有效提高性能，思想上类似CPU中的多级缓存  总结 本文主要介绍了Go内存分配中的一些重要组件以及分配算法。可以看到，其主要思想还是基于TCMalloc的策略，将对象根据大小分类，并使用不同的分配策略。此外，还采用逐层的内存申请策略，大大提高内存分配的性能。\n参考  https://google.github.io/tcmalloc/ http://goog-perftools.sourceforge.net/doc/tcmalloc.html https://medium.com/@ankur_anand/a-visual-guide-to-golang-memory-allocator-from-ground-up-e132258453ed https://www.cnblogs.com/zkweb/p/7880099.html https://www.cnblogs.com/luozhiyun/p/14349331.html https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/  ","permalink":"https://erenming.github.io/posts/memory-allocator-in-go/","summary":"为什么需要内存分配器？ 总说周知，内存作为一种相对稀缺的资源，在操作系统中以虚拟内存的形式来作为一种内存抽象提供给进程，这里可以简单地把它看做一个连续的地址集合{0, 1, 2, ..., M}，由栈空间、堆空间、代码片、数据片等地址空间段组合而成，如下图所示(出自CS:APP3e, Bryant and O\u0026rsquo;Hallaron的第9章第9节)\n这里我们重点关注Heap（堆），堆是一块动态的虚拟内存地址空间。在C语言中，我们通常使用malloc来申请内存以及使用free来释放内存，也许你想问，这样不就足够了吗？但是，这种手动的内存管理会带来很多问题，比如：\n 给程序员带来额外的心智负担，必须得及时释放掉不再使用的内存空间，否则就很容易出现内存泄露 随着内存的不断申请与释放，会产生大量的内存碎片，这将大大降低内存的利用率  因此，正确高效地管理内存空间是非常有必要的，常见的技术实现有Sequential allocation, Free-List allocation等。那么，在Go中，内存是如何被管理的呢？\n 注：此为Go1.13.6的实现逻辑，随版本更替某些细节会有些许不同\n 实现原理 Go的内存分配器是基于TCMalloc设计的，因此我建议你先行查阅，这将有利于理解接下来的内容。\n大量工程经验证明，程序中的小对象占了绝大部分，且生命周期都较为短暂。因此，Go将内存划分为各种类别(Class)，并各自形成Free-List。相较于单一的Free-List分配器，分类后主要有以下优点：\n  其一方面减少不必要的搜索时间，因为对象只需要在其所属类别的空闲链表中搜索即可\n  另一方面减少了内存碎片化，同一类别的空闲链表，每个对象分配的空间都是一样大小(不足则补齐)，因此该链表除非无空闲空间，否则总能分配空间，避免了内存碎片\n  那么，Go内存分配器具体是如何实现的呢？接下来，我将以自顶向下的方式，从宏观到微观，层层拨开她的神秘面纱。\n数据结构 首先，介绍Go内存分配中相关的数据结构。其总体概览图如下所示：\nheapArena 在操作系统中，我们一般把堆看做是一块连续的虚拟内存空间。\nGo将其划分为数个相同大小的连续空间块，称之arena，其中，heapArena则作为arena空间的管理单元，其结构如下所示：\ntype heapArena struct {  bitmap [heapArenaBitmapBytes]byte  spans [pagesPerArena]*mspan  ... }  bitmap: 表示arena区域中的哪些地址保存了对象，哪些地址保存了指针 spans: 表示arena区域中的哪些操作系统页(8K)属于哪些mspan  mheap 然后，则是核心角色mheap了，它是Go内存管理中的核心数据结构，作为全局唯一变量，其结构如下所示：\ntype mheap struct { \tfree mTreap  ...  allspans []*mspan  .","title":"浅析Go内存分配器的实现"},{"content":"最近做了许多有关Go内存优化的工作，总结了一些定位、调优方面的套路和经验，于是，想通过这篇文章与大家分享讨论。\n发现问题 性能优化领域有一条总所周知的铁律，即：不要过早地优化。编写一个程序，首先应该保证其功能的正确性，以及诸如设计是否合理、需求等是否满足，过早地优化只会引入不必要的复杂度以及设计不合理等各种问题。\n那么何时才能开始优化呢？一句话，问题出现时。诸如程序出现频繁OOM，CPU使用率异常偏高等情况。如今，在这微服务盛行的时代，公司内部都会拥有一套或简单或复杂的监控系统，当系统给你发出相关告警时，你就要开始重视起来了。\n问题定位 1. 查看内存曲线 首先，当程序发生OOM时，首先应该查看程序的内存使用量曲线，可以通过现有监控系统查看，或者prometheus之类的开源工具。\n曲线一般都是呈上升趋势，比如goroutine泄露的曲线一般是使用量缓慢上升直至OOM，而内存分配不合理往往时在高负载时快速攀升以致OOM。\n2. 问题复现 这块是可选项，但是最好能保证复现。如果能在本地或debug环境复现问题，这将非常有利于我们反复进行测试和验证。\n3. 使用pprof定位 Go官方工具提供了pporf来专门用以性能问题定位，首先得在程序中开启pprof收集功能，这里假定问题程序已开启pprof。(对这块不够了解的同学，建议通过这两篇文章(1, 2)学习下pprof工具的基本用法)\n接下来，我们复现问题场景，并及时获取heap和groutine的采样信息。\n 获取heap信息: curl http://loalhost:6060/debug/pprof/heap -o h1.out 获取groutine信息：curl http://loalhost:6060/debug/pprof/goroutine -o g1.out  这里你可能想问，这样就够了吗？\n当然不是，只获取一份样本信息是不够的。内存使用量是不断变化的(通常是上升)，因此我们需要的也是期间heap、gourtine信息的变化信息，而非瞬时值。一般来说，我们需要一份正常情况下的样本信息，一份或多份内存升高期间的样本信息。\n数据收集完毕后，我们按照如下3个方面来排查定位。\n排查goroutine泄露 使用命令go tool pprof --base g1.out g2.out ，比较goroutine信息来判断是否有goroutine激增的情况。\n进入交互界面后，输入top命令，查看期间goroutine的变化。\n同时可执行go tool pprof --base g2.out g3.out来验证。我之前写了的一篇实战文章，记录了goroutine泄露的排查过程。\n排查内存使用量 使用命令go tool pprof --base h1.out h2.out，比较当前堆内存的使用量信息来判断内存使用量。\n进入交互界面后，输入top命令，查看期间堆内存使用量的变化。\n排查内存分配量 当上述排查方向都没发现问题时，那就要查看期间是否有大量的内存申请了，以至于GC都来不及回收。使用命令go tool pprof --alloc_space --base h1.out h2.out，通过比较前后内存分配量来判断是否有分配不合理的现象。\n进入交互界面后，输入top命令，查看期间堆内存分配量的变化。\n一般来说，通过上述3个方面的排查，我们基本就能定位出究竟是哪方面的问题导致内存激增了。我们可以通过web命令，更为直观地查看问题函数(方法)的完整调用链。\n问题优化 定位到问题根因后，接下来就是优化阶段了。这个阶段需要对Go本身足够熟悉，还得对问题程序的业务逻辑有所了解。\n我梳理了一些常见的优化手段，仅供参考。实际场景还是得实际分析。\ngoroutine泄露 这种问题还是比较好修复的，需要显式地保证goroutine能正确退出，而非以一些自以为的假设来保证。例如，通过传递context.Context对象来显式退出\ngo func(ctx context.Context) {  for {  select {  case \u0026lt;-ctx.Done():  default:  }  ...  } }(ctx) 对象复用 在一些热点代码处，我们应该避免每次调用都申请新的内存，因为在极端情况下，内存分配速度可能会超过GC的速度，从而导致内存激增。这种情况下，我们可以采取复用对象的方式，例如我们可以使用sync.Pool来复用对象\nvar pool = sync.Pool{New: func() interface{} { return make([]byte, 4096) }}  func fn() { \tbuf := pool.Get().([]byte) // takes from pool or calls New \t// do work \tpool.Put(buf) // returns buf to the pool } 避免[]byte和string转换 在Go中，使用string()或[]byte()来实现[]byte和string的类型转换，会额外申请一块内存来复制。我们可以通过一些技巧来避免复制，例如*(*[]byte)(unsafe.Pointer(\u0026amp;s))来实现string转[]byte\n除此之外，还有很多优化方法，可以看看dave cheney大神的这篇文章，真得写得非常好。\n优化验证 最后一步，我们需要验证优化的结果，毕竟你至少得说服自己，你的优化是的确有成效的。\n除了通过复现测试来验证有效性外的，还可以编写Benchmark测试用例来比较优化前后的内存分配情况（在Benchmark测试用例中加入一行b.ReportAllocs()，即可得到内存分配量信息）\n总结 性能调优是一项必备但是较为困难的技能，不仅需要熟悉语言、操作系统等基本知识，还需要一定的经验积累。\n本文介绍了针对Go程序内存问题的发现、定位、优化以及验证，希望能对你排查内存问题有所帮助（还有某些情况未能没考虑到，欢迎评论区参与讨论）。\n参考  https://dave.cheney.net/high-performance-go-workshop/dotgo-paris.html https://golang.org/pkg/net/http/pprof/ https://www.freecodecamp.org/news/how-i-investigated-memory-leaks-in-go-using-pprof-on-a-large-codebase-4bec4325e192/  ","permalink":"https://erenming.github.io/posts/memory-optimize-best-practice-for-golang/","summary":"最近做了许多有关Go内存优化的工作，总结了一些定位、调优方面的套路和经验，于是，想通过这篇文章与大家分享讨论。\n发现问题 性能优化领域有一条总所周知的铁律，即：不要过早地优化。编写一个程序，首先应该保证其功能的正确性，以及诸如设计是否合理、需求等是否满足，过早地优化只会引入不必要的复杂度以及设计不合理等各种问题。\n那么何时才能开始优化呢？一句话，问题出现时。诸如程序出现频繁OOM，CPU使用率异常偏高等情况。如今，在这微服务盛行的时代，公司内部都会拥有一套或简单或复杂的监控系统，当系统给你发出相关告警时，你就要开始重视起来了。\n问题定位 1. 查看内存曲线 首先，当程序发生OOM时，首先应该查看程序的内存使用量曲线，可以通过现有监控系统查看，或者prometheus之类的开源工具。\n曲线一般都是呈上升趋势，比如goroutine泄露的曲线一般是使用量缓慢上升直至OOM，而内存分配不合理往往时在高负载时快速攀升以致OOM。\n2. 问题复现 这块是可选项，但是最好能保证复现。如果能在本地或debug环境复现问题，这将非常有利于我们反复进行测试和验证。\n3. 使用pprof定位 Go官方工具提供了pporf来专门用以性能问题定位，首先得在程序中开启pprof收集功能，这里假定问题程序已开启pprof。(对这块不够了解的同学，建议通过这两篇文章(1, 2)学习下pprof工具的基本用法)\n接下来，我们复现问题场景，并及时获取heap和groutine的采样信息。\n 获取heap信息: curl http://loalhost:6060/debug/pprof/heap -o h1.out 获取groutine信息：curl http://loalhost:6060/debug/pprof/goroutine -o g1.out  这里你可能想问，这样就够了吗？\n当然不是，只获取一份样本信息是不够的。内存使用量是不断变化的(通常是上升)，因此我们需要的也是期间heap、gourtine信息的变化信息，而非瞬时值。一般来说，我们需要一份正常情况下的样本信息，一份或多份内存升高期间的样本信息。\n数据收集完毕后，我们按照如下3个方面来排查定位。\n排查goroutine泄露 使用命令go tool pprof --base g1.out g2.out ，比较goroutine信息来判断是否有goroutine激增的情况。\n进入交互界面后，输入top命令，查看期间goroutine的变化。\n同时可执行go tool pprof --base g2.out g3.out来验证。我之前写了的一篇实战文章，记录了goroutine泄露的排查过程。\n排查内存使用量 使用命令go tool pprof --base h1.out h2.out，比较当前堆内存的使用量信息来判断内存使用量。\n进入交互界面后，输入top命令，查看期间堆内存使用量的变化。\n排查内存分配量 当上述排查方向都没发现问题时，那就要查看期间是否有大量的内存申请了，以至于GC都来不及回收。使用命令go tool pprof --alloc_space --base h1.out h2.out，通过比较前后内存分配量来判断是否有分配不合理的现象。\n进入交互界面后，输入top命令，查看期间堆内存分配量的变化。\n一般来说，通过上述3个方面的排查，我们基本就能定位出究竟是哪方面的问题导致内存激增了。我们可以通过web命令，更为直观地查看问题函数(方法)的完整调用链。\n问题优化 定位到问题根因后，接下来就是优化阶段了。这个阶段需要对Go本身足够熟悉，还得对问题程序的业务逻辑有所了解。\n我梳理了一些常见的优化手段，仅供参考。实际场景还是得实际分析。\ngoroutine泄露 这种问题还是比较好修复的，需要显式地保证goroutine能正确退出，而非以一些自以为的假设来保证。例如，通过传递context.Context对象来显式退出\ngo func(ctx context.","title":"Golang内存优化实践指南"},{"content":"问题的发现 周五，本是一个风清气爽，令人愉悦的日子。我本还在美滋滋地等待着下班，然而天有不测，有用户反应容器日志看不到了，根据经验我知道，日志采集\u0026amp;收集链路上很可能又发生了阻塞。\n登录目标容器所在机器找到日志采集容器，并娴熟地敲下docker logs --tail 200 -f \u0026lt;container-id\u0026gt;命令，发现确实阻塞了，阻塞原因是上报日志的请求500了，从而不断重试导致日志采集阻塞。\n随后，我找到收集端的容器，查看日志，发现确实有请求报500了，并且抛出了Unknown value type的错误，查看相关代码。\n业务代码：\nif _, err := jsonparser.ArrayEach(body, func(value []byte, dataType jsonparser.ValueType, offset int, err error) {  ... }); err != nil {  return err // 错误抛出点 } jsonparser包中代码：\n显然问题出在了对body的解析上，究竟是什么样的body导致了解析错误呢？接下来，就是tcpdump和wireshark上场的时候了。\n使用Tcpdump抓包 首先，我们通过tcpdump抓到相关的请求。由于日志采集端会不断重试，因此最简单的方法便是登录采集端所在机器，并敲下如下命令tcpdump -i tunl0 dst port 7777 -w td.out ，并等待10-20秒。\n熟悉tcpdump的小伙伴，对这条命令显然已经心领神会了。尽管如此，这里我还是稍微解释下。\n -i tunl0：-i 参数用来指定网卡，由于采集器并没有通过eth0。因此，实战中，有时发现命令正确缺抓不到包的情况时，不妨指定下别的网卡。网络错综复杂，不一定都会通过eth0网卡。 dst port 777： 指定了目标端口作为过滤参数，收集端程序的端口号是7777 -w td.out: 表明将抓包记录保存在td.out文件中，这是因为json body是用base64编码并使用gzip加密后传输的，因此我得使用wireshark来抽离出来。（主要还是wireshark太香了:)，界面友好，操作简单，功能强大）  接着，我用scp命令将td.out文件拷到本地。并使用wireshar打开它\n使用Wireshark分析 打开后，首先映入眼帘的则是上图内容，看起来很多？不要慌，由于我们排查的是http请求，在过滤栏里输入HTTP，过滤掉非HTTP协议的记录。\n我们可以很清楚地发现，所有的HTTP都是发往一个IP的，且长度都是59，显然这些请求都是日志采集端程序不断重试的请求。接下来，我们只需要将某个请求里的body提取出来查看即可。\n很幸运，wireshark提供了这种功能，如上图所示，我们成功提取出来body内容。为bnVsbA==，使用base64解码后为null。\n解决问题 既然body的内容为null，那么调用jsonparser.ArrayEach报错也是意料之中的了，body内容必须得是一个JsonArray。\n然而，采集端为何会发送body为null的请求呢，深入源码，发现了如下一段逻辑。\nfunc (e *jsonEncoder) encode(obj []publisher.Event) (*bytes.Buffer, error) { \tvar events []map[string]interface{} \tfor _, o := range obj { \tm, err := transformMap(o) \tif err != nil { \tlogp.Err(\u0026#34;Fail to transform map with err: %s\u0026#34;, err) \tcontinue \t} \tevents = append(events, m) \t} \tdata, err := json.Marshal(events) \tif err != nil { \treturn nil, errors.Wrap(err, \u0026#34;fail to json marshal events\u0026#34;) \t}  ... } 由于transforMap函数回对obj中的元素进行转换，成功后添加到events中。\n但是，由于使用的是var events []map[string]interface{}这种声明方式，在Golang中，slice的零值为nil，因此events此时的值为nil。而当obj中所有的对象，被transforMap失败时，events使用json序列化后则为null了。\n这里我们需改变evetns的声明方式，使用events := make([]map[string]interface{}, 0)或者events := []map[string]interface{}{}的方式替代，此时events被初始化了，并指向的是一个cap为0的slice对象，其序列化后为[]。\n这样即使没有对象添加到events中，上报的也是一个空数组。\n参考  https://www.cnblogs.com/ggjucheng/archive/2012/01/14/2322659.html https://www.k0rz3n.com/2017/04/17/wireshark/  ","permalink":"https://erenming.github.io/posts/tcpdump-pricate-record/","summary":"问题的发现 周五，本是一个风清气爽，令人愉悦的日子。我本还在美滋滋地等待着下班，然而天有不测，有用户反应容器日志看不到了，根据经验我知道，日志采集\u0026amp;收集链路上很可能又发生了阻塞。\n登录目标容器所在机器找到日志采集容器，并娴熟地敲下docker logs --tail 200 -f \u0026lt;container-id\u0026gt;命令，发现确实阻塞了，阻塞原因是上报日志的请求500了，从而不断重试导致日志采集阻塞。\n随后，我找到收集端的容器，查看日志，发现确实有请求报500了，并且抛出了Unknown value type的错误，查看相关代码。\n业务代码：\nif _, err := jsonparser.ArrayEach(body, func(value []byte, dataType jsonparser.ValueType, offset int, err error) {  ... }); err != nil {  return err // 错误抛出点 } jsonparser包中代码：\n显然问题出在了对body的解析上，究竟是什么样的body导致了解析错误呢？接下来，就是tcpdump和wireshark上场的时候了。\n使用Tcpdump抓包 首先，我们通过tcpdump抓到相关的请求。由于日志采集端会不断重试，因此最简单的方法便是登录采集端所在机器，并敲下如下命令tcpdump -i tunl0 dst port 7777 -w td.out ，并等待10-20秒。\n熟悉tcpdump的小伙伴，对这条命令显然已经心领神会了。尽管如此，这里我还是稍微解释下。\n -i tunl0：-i 参数用来指定网卡，由于采集器并没有通过eth0。因此，实战中，有时发现命令正确缺抓不到包的情况时，不妨指定下别的网卡。网络错综复杂，不一定都会通过eth0网卡。 dst port 777： 指定了目标端口作为过滤参数，收集端程序的端口号是7777 -w td.out: 表明将抓包记录保存在td.out文件中，这是因为json body是用base64编码并使用gzip加密后传输的，因此我得使用wireshark来抽离出来。（主要还是wireshark太香了:)，界面友好，操作简单，功能强大）  接着，我用scp命令将td.out文件拷到本地。并使用wireshar打开它\n使用Wireshark分析 打开后，首先映入眼帘的则是上图内容，看起来很多？不要慌，由于我们排查的是http请求，在过滤栏里输入HTTP，过滤掉非HTTP协议的记录。\n我们可以很清楚地发现，所有的HTTP都是发往一个IP的，且长度都是59，显然这些请求都是日志采集端程序不断重试的请求。接下来，我们只需要将某个请求里的body提取出来查看即可。\n很幸运，wireshark提供了这种功能，如上图所示，我们成功提取出来body内容。为bnVsbA==，使用base64解码后为null。","title":"一次抓包排查实战记录"},{"content":"总所周知，大多数语言中，字典的底层是哈希表，而且其算法也是十分清晰的。无论采用链表法还是开放寻址法，我们都能实现一个简单的哈希表结构。对于Go来说，它是具体如何实现哈希表的呢？以及，采取了哪些优化策略呢？\n内存模型 map在内存的总体结构如下图所示。\n头部结构体hmap type hmap struct { \tcount int // 键值对个数 \tflags uint8 \tB uint8 // 2^B = 桶数量 \tnoverflow uint16 // 溢出桶的个数 \thash0 uint32 // hash seed  \tbuckets unsafe.Pointer // 哈希桶 \toldbuckets unsafe.Pointer // 原哈希桶，扩容时为非空 \tnevacuate uintptr // 扩容进度，地址小于它的桶已被迁移了  \textra *mapextra // optional fields } hmap即为map编译后的内存表示，这里需要注意的有两点。\n B的值是根据负载因子(LoadFactor)以及存储的键值对数量，在创建或扩容时动态改变 buckets是一个指针，它指向一个bmap结构  桶结构体bmap type bmap struct { \t// tophash数组可以看做键值对的索引 \ttophash [bucketCnt]uint8 \t// 实际上编译器会动态添加下述属性  // keys [8]keytype  // values [8]valuetype  // padding uinptr  // overflow uinptr } 虽然bmap结构体中只有一个tophash数组，但实际上，其后跟着8个key的槽位、8个value的槽位、padding以及一个overflow指针。如下图所示\n这里，Go做了优化。\n 这里并没有把key/value作为一个entry，而是分开存储。主要是为了节省内存，有时可以避免使用padding(额外的内存)来对齐，比如map[int64]int8就完全不需要padding。  查找操作 查找操作总体和链表法的哈希表查找类似，即key \u0026mdash;\u0026gt; hashFunc(key) \u0026mdash;\u0026gt; mask(hash) \u0026mdash;\u0026gt; 桶的位置 \u0026mdash;\u0026gt; 遍历链表。其主要代码如下所示\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { \t... \talg := t.key.alg \thash := alg.hash(key, uintptr(h.hash0)) \tm := bucketMask(h.B) \t// 计算得到桶的位置bucket-k \tb := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize)))  // 若正在扩容，老buckets则为非空 \t// 若bucket-k在老的buckets数组中，未被迁移，则使用老的 \tif c := h.oldbuckets; c != nil { \tif !h.sameSizeGrow() { \t// There used to be half as many buckets; mask down one more power of two. \tm \u0026gt;\u0026gt;= 1 \t} \toldb := (*bmap)(add(c, (hash\u0026amp;m)*uintptr(t.bucketsize))) \tif !evacuated(oldb) { \tb = oldb \t} \t} \t// 根据tophash(hash), 在bucket-k中的tophash中查找key \ttop := tophash(hash)  // 找到对应的bucket后，遍历查找对应的key/value bucketloop: \tfor ; b != nil; b = b.overflow(t) { \tfor i := uintptr(0); i \u0026lt; bucketCnt; i++ { \t... \t// 计算第i个位置的key的地址 \tk := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) \tif t.indirectkey() { \tk = *((*unsafe.Pointer)(k)) \t} \t// 比较tophash[i]上的k是否与目标key相等 \tif alg.equal(key, k) {  // 计算value的地址 \tv := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) \tif t.indirectvalue() { \tv = *((*unsafe.Pointer)(v)) \t} \treturn v \t} \t} \t} \t// 若最终还是没找到，则返回nil \treturn unsafe.Pointer(\u0026amp;zeroVal[0]) } 首先，Go通过对应类型的alg.hash计算得到hash值（各种类型的hash\u0026amp;equal函数定义），取后B位作为buckets数组的下标(实际上为取余)，取高8位作为tophash的下标。\n然后，通过一个嵌套循环查找目标key：外层循环是遍历一个bmap单链表，它们通过overflow指针相连；内层循环则遍历tophash数组，逐个比较，当匹配成功时，则计算得到实际key的地址，比较两者，成功则返回。如下图所示\n这里，Go做了如下优化。\n 使用tophash数组，作为索引，用以判断key是否存在该bmap中，若确实存在，再使用较为耗时的比较算法判断key是否相等。  除了查找操作，map的插入、删除以及扩容操作也十分值得学习，大家可以去查阅相关源码\n本人才疏学浅，文章难免有些不足之处，非常欢迎大大们评论指出。\n参考  https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics#easy-footnote-1-3224 https://github.com/golang/go/blob/master/src/runtime/map.go https://studygolang.com/articles/25134 https://www.linkinstar.wiki/2019/06/03/golang/source-code/graphic-golang-map/ [https://github.com/qcrao/Go-Questions/blob/master/map/map%20%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88.md](https://github.com/qcrao/Go-Questions/blob/master/map/map 的底层实现原理是什么.md)  ","permalink":"https://erenming.github.io/posts/map-in-go/","summary":"总所周知，大多数语言中，字典的底层是哈希表，而且其算法也是十分清晰的。无论采用链表法还是开放寻址法，我们都能实现一个简单的哈希表结构。对于Go来说，它是具体如何实现哈希表的呢？以及，采取了哪些优化策略呢？\n内存模型 map在内存的总体结构如下图所示。\n头部结构体hmap type hmap struct { \tcount int // 键值对个数 \tflags uint8 \tB uint8 // 2^B = 桶数量 \tnoverflow uint16 // 溢出桶的个数 \thash0 uint32 // hash seed  \tbuckets unsafe.Pointer // 哈希桶 \toldbuckets unsafe.Pointer // 原哈希桶，扩容时为非空 \tnevacuate uintptr // 扩容进度，地址小于它的桶已被迁移了  \textra *mapextra // optional fields } hmap即为map编译后的内存表示，这里需要注意的有两点。\n B的值是根据负载因子(LoadFactor)以及存储的键值对数量，在创建或扩容时动态改变 buckets是一个指针，它指向一个bmap结构  桶结构体bmap type bmap struct { \t// tophash数组可以看做键值对的索引 \ttophash [bucketCnt]uint8 \t// 实际上编译器会动态添加下述属性  // keys [8]keytype  // values [8]valuetype  // padding uinptr  // overflow uinptr } 虽然bmap结构体中只有一个tophash数组，但实际上，其后跟着8个key的槽位、8个value的槽位、padding以及一个overflow指针。如下图所示","title":"Golang中的map实现"},{"content":"在编写web应用中，我们常常会遇到这样的需求，比如，我们需要上报每个API的运行时间到运维监控系统。这时候你可以像下述代码一样将统计的逻辑写到每个路由函数中。\nfunc someApi(w http.ResponseWriter, r *http.Request) { \tstart := time.Now() \t// your logic \tmetrics.Upload(time.Since(start)) } 然而，这显然有悖DRY原则，我们需要将这些非业务逻辑剥离出来以实现解耦。这时候，中间件就能派上用场了，为了简单起见，我们这里将采用标准库net/http来实现。\n准备工作 func hello(w http.ResponseWriter, r *http.Request) { \tlog.Println(\u0026#34;execute hello func\u0026#34;) \tw.Write([]byte(\u0026#34;hello, world\u0026#34;)) }  func main() { \thttp.Handle(\u0026#34;/\u0026#34;, http.HandlerFunc(hello)) \thttp.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) } 这里，我们创建了一个hello函数并将其转换成一个Handler用以处理HTTP请求。\n中间件的实现 func middlewareOne(next http.Handler) http.Handler { \treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { \tlog.Println(\u0026#34;middleware one start\u0026#34;) // before logic \tnext.ServeHTTP(w, r) \tlog.Println(\u0026#34;middleware one end\u0026#34;) // after logic \t}) } 这里，我们实现了一个中间件函数middlewareOne，它接收一个next的参数其类型为http.Handler并返回一个新的http.Handler。而next.ServeHTTP(w, r)会回调next函数自身，即next(w, r)。看到这里，你可能会有点懵，我们需要先复习一下Handler，HandlerFunc，ServeHTTP三者的关系。\n下面是三者的定义：\n// A Handler responds to an HTTP request. type Handler interface { \tServeHTTP(ResponseWriter, *Request) }  type HandlerFunc func(ResponseWriter, *Request)  // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { \tf(w, r) } Handler是一个接口，用以处理HTTP请求，换句话说，一个函数若想成为一个路由函数必须得是一个Handler接口。\nHandlerFunc是一个签名为func(ResponseWriter, *Request)的函数类型，其实现了ServerHTTP方法且签名相同，故HandleFunc是一个Handler，其ServerHTTP方法调用HandlerFunc自身。\n三者关系如下图所示：\n好了，接下来我们将中间件函数应用到我们的Handler上。\nfunc main() { \thttp.Handle(\u0026#34;/\u0026#34;, middlewareOne(http.HandlerFunc(hello))) \thttp.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) } 运行程序，然后访问http://127.0.0.1:3000/，控制台将输出如下结果。\n2019/12/middleware one start 2019/12/execute hello func 2019/12/middleware one end 当然，如果你想应用多个中间件，你只需要再套上一层，例如下述代码：\nfunc middlewareTwo(next http.Handler) http.Handler { \treturn http.HandlerFunc(func (w http.ResponseWriter, r *http.Request) { \tlog.Println(\u0026#34;middleware two start\u0026#34;) \tnext.ServeHTTP(w, r) \tlog.Println(\u0026#34;middleware two end\u0026#34;) \t}) }  func main() { \thttp.Handle(\u0026#34;/\u0026#34;, middlewareTwo(middlewareOne(http.HandlerFunc(hello)))) \thttp.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) } 我画出了该函数链的执行流程，如下图所示：\n可以看到，如果我们把路由函数hello看做为汉堡里的肉饼，中间件函数看做成面包。那么，middlewareOne包住了肉饼hello，而middlewareTwo又包住了middlewareTwo。\n总结  中间件函数与Python中的装饰器函数十分类似，都是在原函数逻辑不变的条件下进行扩展。 对于Web框架而言，类似于Flask里面的before_request和after_request钩子函数，next.ServeHTTP之前逻辑的等同于before_request里的逻辑、之后的等同于于after_request里的逻辑。 在业务开发中，我们应尽量将非业务逻辑抽象到中间件中，实现代码的松耦合与易扩展。  本人才疏学浅，文章难免有些不足之处，非常欢迎大家评论指出。\n参考  https://github.com/chai2010/advanced-go-programming-book/blob/master/ch5-web/ch5-03-middleware.md https://www.alexedwards.net/blog/making-and-using-middleware https://golang.org/doc/effective_go.html#interface_methods ","permalink":"https://erenming.github.io/posts/understand-middleware/","summary":"\u003cp\u003e在编写web应用中，我们常常会遇到这样的需求，比如，我们需要上报每个API的运行时间到运维监控系统。这时候你可以像下述代码一样将统计的逻辑写到每个路由函数中。\u003c/p\u003e","title":"用Golang实现并理解Web中间件"},{"content":"说到string类型，我们往往都能很熟练地对它进行各种处理，包括迭代、随机访问和匹配等等操作。然而在工作中，我发现迭代一个字符串产生的字符的类型与随机访问一个字符的类型却并不相同，为什么会这么奇怪呢？于是我决定一探究竟\nstring 简析 在Golang中，字符串本质上看一看做一个只读的字节切片(仅比切片少了一个Cap属性)。它的底层结构我们可以查看reflect.StringHeader得到:\ntype StringHeader struct {  Data uintptr  Len int } 例如针对字符串\u0026quot;你好\u0026quot;，其在内存中的表示如下图所示： Go的源文件默认使用UTF-8编码，所有的字符串字面量一般也是UTF-8编码的，故这里的你编码为\\xe4\\xbd\\xa0，好编码为\\xe5\\xa5\\xbd。UTF-8编码不是我们讨论的重点，具体可参考这篇博客。\n这里我们运行下述代码\n\ts := []byte{0xe4, 0xbd, 0xa0} \tfmt.Printf(\u0026#34;char is %s\u0026#34;, string(s)) 得到运行结果char is 你。\n虽然字符串并非切片，但是支持切片操作。对于同一字面量，不同的字符串变量指向相同的底层数组，这是因为字符串是只读的，为了节省内存，相同字面量的字符串通常对应于同一字符串常量。例如：\n\ts := \u0026#34;hello, world\u0026#34; \ts1 := \u0026#34;hello, world\u0026#34; \ts2 := \u0026#34;hello, world\u0026#34;[7:] \tfmt.Printf(\u0026#34;%d \\n\u0026#34;, (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)).Data) // 17598361 \tfmt.Printf(\u0026#34;%d \\n\u0026#34;, (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s1)).Data) // 17598361 \tfmt.Printf(\u0026#34;%d \\n\u0026#34;, (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s2)).Data) // 17598368 可以看到，三者均指向同一个底层数组。对于s1, s2由于是同一字符串常量hello, world，故指向一个底层数组，以h为起始位置；而s2是字面量hello, world的切片操作后生成的字符串，也指向同一字节底层数组，不过是以w为起始位置。\n迭代字符串 当我们使用for range迭代字符串时，每次迭代Go都会用UTF-8解码出一个rune类型的字符，且索引为当前rune的起始位置(以字节为最下单位)。\n\tfor index, char := range \u0026#34;你好\u0026#34; { \tfmt.Printf(\u0026#34;start at %d, Unicode = %U, char = %c\\n\u0026#34;, index, char, char) \t} 得到运行结果\nstart at 0, Unicode = U+4F60, char = 你 start at 3, Unicode = U+597D, char = 好 随机访问字符串 当我们用下标访问字符串时，返回的值为单个字节，而我们直觉中，应该返回一个字符才合理。这还是因为string的后端数组是一个字节切片而非一个字符切片\n\ts := \u0026#34;你好\u0026#34; \tfmt.Printf(\u0026#34;s[%d] = %q, hex = %x, Unicode = %U\u0026#34;, 1, s[1], s[1], s[1]) 得到运行结果\ns[1] = \u0026#39;½\u0026#39;, hex = bd, Unicode = U+00BD 这里我们打印出来索引位置为1的字节，为0xbd，其Unicode为U+00BD, 代表的字符为½。(你可以通过这里查询)\n到底什么是rune、字符和字节 字节：即byte，它由8个位组成，即1byte = 8bit，是计算机中的基本计量单位，在Go中为byte类型，其实际上为uint8的别名\n字符：字符的概念比较模糊，在Unicode中通常用code point来表示。在我的理解里，是一种信息单元(例如一个符号、字母等)\nrune：其实际上是int32的别名，但是为了方便将字符与整数值区分开，从而新增了rune类型代表一个字符。\n总结  通过下标访问字符串时，返回的是一个字节，这往往与我们的直觉相背。所以，如果你一定要通过下标访问字符串，可以先将其转换为[]rune类型 字符串可以看做是一个只读字节切片, 支持切片操作。  本人才疏学浅，文章难免有些不足之处，非常欢迎大家评论指出。\n参考  https://chorer.github.io/2019/09/16/CB-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9Fcp1/ https://draveness.me/golang/datastructure/golang-string.html https://berryjam.github.io/2018/03/%E4%BB%8Egolang%E5%AD%97%E7%AC%A6%E4%B8%B2string%E9%81%8D%E5%8E%86%E8%AF%B4%E8%B5%B7/ https://en.wikipedia.org/wiki/Code_point https://github.com/chai2010/advanced-go-programming-book/blob/master/ch1-basic/ch1-03-array-string-and-slice.md ","permalink":"https://erenming.github.io/posts/string-in-golang/","summary":"\u003cp\u003e说到\u003ccode\u003estring\u003c/code\u003e类型，我们往往都能很熟练地对它进行各种处理，包括迭代、随机访问和匹配等等操作。然而在工作中，我发现迭代一个字符串产生的字符的类型与随机访问一个字符的类型却并不相同，为什么会这么奇怪呢？于是我决定一探究竟\u003c/p\u003e","title":"Golang中的string实现"},{"content":"嗨，我的朋友！\n欢迎来到我的技术博客，我的名字叫姜小明（erenming)。我的座右铭是Keep it simple stupid，没错，就是大名鼎鼎的KISS原则。\n一名程序员，使用Go作为我的主要开发语言，目前专注于可观测性，云原生领域。\n最后，欢迎与我联系，一起探讨技术 :P\n","permalink":"https://erenming.github.io/about/","summary":"嗨，我的朋友！\n欢迎来到我的技术博客，我的名字叫姜小明（erenming)。我的座右铭是Keep it simple stupid，没错，就是大名鼎鼎的KISS原则。\n一名程序员，使用Go作为我的主要开发语言，目前专注于可观测性，云原生领域。\n最后，欢迎与我联系，一起探讨技术 :P","title":"About"},{"content":"仅以记录我在读、已读、预读之书。\n在读 22.06-22.12  《知识变现》：技术人还是看看，学习下如何提升影响力 《Observability Engineering》：关于可观测领域比较全面的书了，从业者可重点关注第1、2、4章节 《stop reading news》：确实很有道理，这年头新闻量与日俱增，浪费时间且易过度焦虑 《深入理解Kafka：核心设计与实践原理》：工作中Kafka用的也比较多，加强下 《ClickHouse原理解析与应用实践》：ClickHouse需要再深入学习下，中文版好读:P 《Systems Performance: Enterprise and the Cloud》：性能之巅第二版，好好看看（30%） 《Dive into Refactoring》： 重构方面的书  预读  《Building Event Driven Microservice》 《Programming Rust》：学习下最先进的Rust吧 《Queueing theory in Action》：排队理论，工作中队列的使用无处不在，需要学习下  已读  《Real-Time Analytics Techniques to Analyze》：70%   介绍了流式系统的常见设计和考虑，还是不错的，对我设计监控数据链路有帮助\n  《Kubernetes In Action》：100%   挺不错的一本书，Kubernetes的东西基本都涵盖了，其中的各种流程图有助于理解各组件的工作机制\n  《Designing Data Intensive Applications》：200%   读了两遍，强烈推荐，尤其是第一部分和第二部分。读完之后, 能对现如今的各种分布式数据组件的有更深的理解，配合Mit-6.824食用更佳\n  《Operating Systems: Three Easy Pieces》: 45%   主要看了CPU部分。以更为通俗易懂、诙谐的方式讲解操作系统，尤其是每章之后的教授问答环节。不过感觉还是作为教科书的目的编写的\n  《GO专家编程》：30%   华为大佬编写，主要对Go语言各种实现原理进行讲解。对实现能有大概的理解，不过也没有太深入细节，可以面试前看看。\n  《垃圾回收的算法与实现》：60%   介绍了各种GC算法和具体语言的实现，可以重点看看算法篇，对了解GC很有帮助，不过我当时还是看不太懂，可能需要再修炼修炼才能更好理解\n ","permalink":"https://erenming.github.io/readings/","summary":"仅以记录我在读、已读、预读之书。\n在读 22.06-22.12  《知识变现》：技术人还是看看，学习下如何提升影响力 《Observability Engineering》：关于可观测领域比较全面的书了，从业者可重点关注第1、2、4章节 《stop reading news》：确实很有道理，这年头新闻量与日俱增，浪费时间且易过度焦虑 《深入理解Kafka：核心设计与实践原理》：工作中Kafka用的也比较多，加强下 《ClickHouse原理解析与应用实践》：ClickHouse需要再深入学习下，中文版好读:P 《Systems Performance: Enterprise and the Cloud》：性能之巅第二版，好好看看（30%） 《Dive into Refactoring》： 重构方面的书  预读  《Building Event Driven Microservice》 《Programming Rust》：学习下最先进的Rust吧 《Queueing theory in Action》：排队理论，工作中队列的使用无处不在，需要学习下  已读  《Real-Time Analytics Techniques to Analyze》：70%   介绍了流式系统的常见设计和考虑，还是不错的，对我设计监控数据链路有帮助\n  《Kubernetes In Action》：100%   挺不错的一本书，Kubernetes的东西基本都涵盖了，其中的各种流程图有助于理解各组件的工作机制\n  《Designing Data Intensive Applications》：200%   读了两遍，强烈推荐，尤其是第一部分和第二部分。读完之后, 能对现如今的各种分布式数据组件的有更深的理解，配合Mit-6.824食用更佳\n  《Operating Systems: Three Easy Pieces》: 45%   主要看了CPU部分。以更为通俗易懂、诙谐的方式讲解操作系统，尤其是每章之后的教授问答环节。不过感觉还是作为教科书的目的编写的","title":"Readings"}]